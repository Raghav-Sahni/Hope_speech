{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from embeddings_loader import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_labels, dev_labels, test_labels = load_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_replacement = {\n",
    "    'Hope_speech': 0,\n",
    "    'Non_hope_speech': 1,\n",
    "    'not-English': 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace labels with numbers\n",
    "train_labels = [label_replacement[label] for label in train_labels]\n",
    "dev_labels = [label_replacement[label] for label in dev_labels]\n",
    "test_labels = [label_replacement[label] for label in test_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_reg = LogisticRegression()\n",
    "grid = {\"penalty\" : ['l1', 'l2'], \"C\" : np.logspace(-3,3,7), \"solver\" : ['lbfgs', 'liblinear'], \"max_iter\":[1000]}\n",
    "gridsearch = GridSearchCV(logistic_reg, param_grid = grid, scoring = \"f1_micro\", n_jobs=os.cpu_count()//2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glove Twitter 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt25_train, gt25_dev, gt25_test = load_glove_twitter_25()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set all NaN values to 0\n",
    "gt25_train = np.nan_to_num(gt25_train)\n",
    "gt25_dev = np.nan_to_num(gt25_dev)\n",
    "gt25_test = np.nan_to_num(gt25_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "35 fits failed out of a total of 140.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.91261752 0.91283719 0.91283719        nan 0.91283719\n",
      " 0.91283718 0.91288112        nan 0.91283722 0.9117389  0.91283719\n",
      "        nan 0.91138747 0.91121174 0.9113435         nan 0.91121173\n",
      " 0.91107994 0.91112386        nan 0.91121173 0.91116781 0.91121173\n",
      "        nan 0.91121173 0.91116781 0.91121173]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "grid_results = gridsearch.fit(gt25_train, train_labels)\n",
    "best_params = grid_results.best_params_\n",
    "logistic_reg = grid_results.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.01, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logistic_reg = logistic_reg.fit(gt25_train, train_labels)\n",
    "save_model(logistic_reg, \"logistic_reg_gt25.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = logistic_reg.predict(gt25_train)\n",
    "dev_preds = logistic_reg.predict(gt25_dev)\n",
    "test_preds = logistic_reg.predict(gt25_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Train:  0.9128811176522273\n",
      "Accuracy Dev:  0.9036229335209286\n",
      "Accuracy Test:  0.9111033028812369\n",
      "Weighted F1 Train:  0.8713494955888584\n",
      "Weighted F1 Dev:  0.85787410059692\n",
      "Weighted F1 Test:  0.8687225094212346\n",
      "Macro F1 Train:  0.3184911585290693\n",
      "Macro F1 Dev:  0.31645725548164577\n",
      "Macro F1 Test:  0.31782803211374644\n",
      "Micro F1 Train:  0.9128811176522273\n",
      "Micro F1 Dev:  0.9036229335209286\n",
      "Micro F1 Test:  0.9111033028812369\n",
      "Weighted Recall Train:  0.9128811176522273\n",
      "Weighted Recall Dev:  0.9036229335209286\n",
      "Weighted Recall Test:  0.9111033028812369\n",
      "Macro Recall Train:  0.3335032279986408\n",
      "Macro Recall Dev:  0.3333333333333333\n",
      "Macro Recall Test:  0.3333333333333333\n",
      "Micro Recall Train:  0.9128811176522273\n",
      "Micro Recall Dev:  0.9036229335209286\n",
      "Micro Recall Test:  0.9111033028812369\n",
      "Confusion Matrix Train: \n",
      "[[    1  1961     0]\n",
      " [    0 20778     0]\n",
      " [    0    22     0]]\n",
      "Confusion Matrix Dev: \n",
      "[[   0  272    0]\n",
      " [   0 2569    0]\n",
      " [   0    2    0]]\n",
      "Confusion Matrix Test: \n",
      "[[   0  250    0]\n",
      " [   0 2593    0]\n",
      " [   0    3    0]]\n"
     ]
    }
   ],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FastText 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft300_train, ft300_dev, ft300_test = load_fasttext_300()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set all NaN values to 0\n",
    "ft300_train = np.nan_to_num(ft300_train)\n",
    "ft300_dev = np.nan_to_num(ft300_dev)\n",
    "ft300_test = np.nan_to_num(ft300_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "35 fits failed out of a total of 140.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.91283719 0.91283719 0.91283719        nan 0.91283719\n",
      " 0.91283719 0.91283719        nan 0.91283719 0.91283719 0.91283719\n",
      "        nan 0.913672   0.9139795  0.91375977        nan 0.91068463\n",
      " 0.91261765 0.91314482        nan 0.90954239 0.90993777 0.91024527\n",
      "        nan 0.90835616 0.90888346 0.9097181 ]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "grid_results = gridsearch.fit(ft300_train, train_labels)\n",
    "best_params = grid_results.best_params_\n",
    "logistic_reg = grid_results.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1.0, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_reg = logistic_reg.fit(ft300_train, train_labels)\n",
    "save_model(logistic_reg, \"logistic_reg_ft300.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = logistic_reg.predict(ft300_train)\n",
    "dev_preds = logistic_reg.predict(ft300_dev)\n",
    "test_preds = logistic_reg.predict(ft300_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Train:  0.9142869695105879\n",
      "Accuracy Dev:  0.9064368624692226\n",
      "Accuracy Test:  0.9125087842586086\n",
      "Weighted F1 Train:  0.8788590497232962\n",
      "Weighted F1 Dev:  0.8693550919504244\n",
      "Weighted F1 Test:  0.8752741881019258\n",
      "Macro F1 Train:  0.34563763231027994\n",
      "Macro F1 Dev:  0.3529130466769665\n",
      "Macro F1 Test:  0.3407610668900991\n",
      "Micro F1 Train:  0.9142869695105879\n",
      "Micro F1 Dev:  0.9064368624692226\n",
      "Micro F1 Test:  0.9125087842586086\n",
      "Weighted Recall Train:  0.9142869695105879\n",
      "Weighted Recall Dev:  0.9064368624692226\n",
      "Weighted Recall Test:  0.9125087842586086\n",
      "Macro Recall Train:  0.3470940162637715\n",
      "Macro Recall Dev:  0.35190315908379705\n",
      "Macro Recall Test:  0.34469057719501217\n",
      "Micro Recall Train:  0.9142869695105879\n",
      "Micro Recall Dev:  0.9064368624692226\n",
      "Micro Recall Test:  0.9125087842586086\n",
      "Confusion Matrix Train: \n",
      "[[   86  1876     0]\n",
      " [   53 20725     0]\n",
      " [    0    22     0]]\n",
      "Confusion Matrix Dev: \n",
      "[[  16  256    0]\n",
      " [   8 2561    0]\n",
      " [   0    2    0]]\n",
      "Confusion Matrix Test: \n",
      "[[   9  241    0]\n",
      " [   5 2588    0]\n",
      " [   0    3    0]]\n"
     ]
    }
   ],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v300_train, w2v300_dev, w2v300_test = load_word2vec_300()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set all NaN values to 0\n",
    "w2v300_train = np.nan_to_num(w2v300_train)\n",
    "w2v300_dev = np.nan_to_num(w2v300_dev)\n",
    "w2v300_test = np.nan_to_num(w2v300_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "35 fits failed out of a total of 140.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.91283719 0.91283719 0.91283719        nan 0.91283719\n",
      " 0.91283719 0.91283719        nan 0.91305684 0.91402345 0.91367192\n",
      "        nan 0.9116072  0.91204648 0.91239798        nan 0.91059676\n",
      " 0.91108    0.91094821        nan 0.90984987 0.9100256  0.9102892\n",
      "        nan 0.90901516 0.90875155 0.91015743]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "grid_results = gridsearch.fit(w2v300_train, train_labels)\n",
    "best_params = grid_results.best_params_\n",
    "logistic_reg = grid_results.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_reg = logistic_reg.fit(w2v300_train, train_labels)\n",
    "save_model(logistic_reg, \"logistic_reg_w2v300.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = logistic_reg.predict(w2v300_train)\n",
    "dev_preds = logistic_reg.predict(w2v300_dev)\n",
    "test_preds = logistic_reg.predict(w2v300_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Train:  0.914243036640014\n",
      "Accuracy Dev:  0.9064368624692226\n",
      "Accuracy Test:  0.9104005621925509\n",
      "Weighted F1 Train:  0.8791989825142942\n",
      "Weighted F1 Dev:  0.8699112143150298\n",
      "Weighted F1 Test:  0.8740860037544342\n",
      "Macro F1 Train:  0.3470623060519927\n",
      "Macro F1 Dev:  0.35490221977435915\n",
      "Macro F1 Test:  0.3398700047159173\n",
      "Micro F1 Train:  0.914243036640014\n",
      "Micro F1 Dev:  0.9064368624692226\n",
      "Micro F1 Test:  0.9104005621925509\n",
      "Weighted Recall Train:  0.914243036640014\n",
      "Weighted Recall Dev:  0.9064368624692226\n",
      "Weighted Recall Test:  0.9104005621925509\n",
      "Macro Recall Train:  0.3478472339352893\n",
      "Macro Recall Dev:  0.35299889710652654\n",
      "Macro Recall Test:  0.3439192698290268\n",
      "Micro Recall Train:  0.914243036640014\n",
      "Micro Recall Dev:  0.9064368624692226\n",
      "Micro Recall Test:  0.9104005621925509\n",
      "Confusion Matrix Train: \n",
      "[[   91  1871     0]\n",
      " [   59 20719     0]\n",
      " [    0    22     0]]\n",
      "Confusion Matrix Dev: \n",
      "[[  17  255    0]\n",
      " [   9 2560    0]\n",
      " [   0    2    0]]\n",
      "Confusion Matrix Test: \n",
      "[[   9  241    0]\n",
      " [  11 2582    0]\n",
      " [   0    3    0]]\n"
     ]
    }
   ],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF PCA (1000 Dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_pca_train, tfidf_pca_dev, tfidf_pca_test = load_tfidf_pca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "35 fits failed out of a total of 140.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.91283719 0.91283719 0.91283719        nan 0.91283719\n",
      " 0.91283719 0.91283719        nan 0.91516568 0.91534137 0.91318865\n",
      "        nan 0.9237325  0.92478701 0.92298575        nan 0.92421593\n",
      " 0.92491883 0.92597322        nan 0.92210709 0.92272217 0.92346903\n",
      "        nan 0.91991043 0.92087696 0.92144811]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "grid_results = gridsearch.fit(tfidf_pca_train, train_labels)\n",
    "best_params = grid_results.best_params_\n",
    "logistic_reg = grid_results.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10.0, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logistic_reg = logistic_reg.fit(tfidf_pca_train, train_labels)\n",
    "save_model(logistic_reg, \"logistic_reg_tfidf_pca.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = logistic_reg.predict(tfidf_pca_train)\n",
    "dev_preds = logistic_reg.predict(tfidf_pca_dev)\n",
    "test_preds = logistic_reg.predict(tfidf_pca_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Train:  0.9358140760917318\n",
      "Accuracy Dev:  0.9162856137882518\n",
      "Accuracy Test:  0.9226985242445538\n",
      "Weighted F1 Train:  0.9260862642946405\n",
      "Weighted F1 Dev:  0.9051578788710987\n",
      "Weighted F1 Test:  0.9116437521939569\n",
      "Macro F1 Train:  0.4944128742208025\n",
      "Macro F1 Dev:  0.466049692708707\n",
      "Macro F1 Test:  0.46496183555007087\n",
      "Micro F1 Train:  0.9358140760917318\n",
      "Micro F1 Dev:  0.9162856137882518\n",
      "Micro F1 Test:  0.9226985242445538\n",
      "Weighted Recall Train:  0.9358140760917318\n",
      "Weighted Recall Dev:  0.9162856137882518\n",
      "Weighted Recall Test:  0.9226985242445538\n",
      "Macro Recall Train:  0.4604974052674116\n",
      "Macro Recall Dev:  0.44100378571046944\n",
      "Macro Recall Test:  0.4387772207224579\n",
      "Micro Recall Train:  0.9358140760917318\n",
      "Micro Recall Dev:  0.9162856137882518\n",
      "Micro Recall Test:  0.9226985242445538\n",
      "Confusion Matrix Train: \n",
      "[[  772  1190     0]\n",
      " [  249 20529     0]\n",
      " [    0    22     0]]\n",
      "Confusion Matrix Dev: \n",
      "[[  94  178    0]\n",
      " [  58 2511    0]\n",
      " [   0    2    0]]\n",
      "Confusion Matrix Test: \n",
      "[[  84  166    0]\n",
      " [  51 2542    0]\n",
      " [   0    3    0]]\n"
     ]
    }
   ],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seentence Transformer Faster No PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, dev, test = load_sent_trans_fast_no_pca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "35 fits failed out of a total of 140.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.91283719 0.91283719 0.91283719        nan 0.91283719\n",
      " 0.91283719 0.91283719        nan 0.91854842 0.92417184 0.92100861\n",
      "        nan 0.92562145 0.92548971 0.92575326        nan 0.92452321\n",
      " 0.92478678 0.9253579         nan 0.92461111 0.92447931 0.92461107\n",
      "        nan 0.92469899 0.92439146 0.92465505]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "grid_results = gridsearch.fit(train, train_labels)\n",
    "best_params = grid_results.best_params_\n",
    "logistic_reg = grid_results.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1.0, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logistic_reg = logistic_reg.fit(train, train_labels)\n",
    "save_model(logistic_reg, \"logistic_reg_sent_trans_fast_no_pca.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = logistic_reg.predict(train)\n",
    "dev_preds = logistic_reg.predict(dev)\n",
    "test_preds = logistic_reg.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Train:  0.9288726825410772\n",
      "Accuracy Dev:  0.9176925782623989\n",
      "Accuracy Test:  0.9248067463106114\n",
      "Weighted F1 Train:  0.9153117608065434\n",
      "Weighted F1 Dev:  0.9013103392248377\n",
      "Weighted F1 Test:  0.9112775168450953\n",
      "Macro F1 Train:  0.4641122403976934\n",
      "Macro F1 Dev:  0.44951195604016525\n",
      "Macro F1 Test:  0.45951751150945497\n",
      "Micro F1 Train:  0.9288726825410772\n",
      "Micro F1 Dev:  0.9176925782623989\n",
      "Micro F1 Test:  0.9248067463106114\n",
      "Weighted Recall Train:  0.9288726825410772\n",
      "Weighted Recall Dev:  0.9176925782623989\n",
      "Weighted Recall Test:  0.9248067463106114\n",
      "Macro Recall Train:  0.4319616755313121\n",
      "Macro Recall Dev:  0.4207037719720041\n",
      "Macro Recall Test:  0.4299102712430904\n",
      "Micro Recall Train:  0.9288726825410772\n",
      "Micro Recall Dev:  0.9176925782623989\n",
      "Micro Recall Test:  0.9248067463106114\n",
      "Confusion Matrix Train: \n",
      "[[  603  1359     0]\n",
      " [  238 20540     0]\n",
      " [    0    22     0]]\n",
      "Confusion Matrix Dev: \n",
      "[[  75  197    0]\n",
      " [  35 2534    0]\n",
      " [   0    2    0]]\n",
      "Confusion Matrix Test: \n",
      "[[  76  174    0]\n",
      " [  37 2556    0]\n",
      " [   0    3    0]]\n"
     ]
    }
   ],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Transformer Faster PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, dev, test = load_sent_trans_fast_pca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "35 fits failed out of a total of 140.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.91283719 0.91283719 0.91283719        nan 0.91283719\n",
      " 0.91283719 0.91283719        nan 0.9224585  0.92430363 0.92092078\n",
      "        nan 0.92509426 0.92478672 0.9249625         nan 0.92456711\n",
      " 0.92469889 0.92469884        nan 0.92465498 0.92465495 0.92461103\n",
      "        nan 0.92456711 0.92434744 0.92465498]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "grid_results = gridsearch.fit(train, train_labels)\n",
    "best_params = grid_results.best_params_\n",
    "logistic_reg = grid_results.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1.0, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logistic_reg = logistic_reg.fit(train, train_labels)\n",
    "save_model(logistic_reg, \"logistic_reg_sent_trans_fast_pca.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = logistic_reg.predict(train)\n",
    "dev_preds =logistic_reg.predict(dev)\n",
    "test_preds = logistic_reg.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Train:  0.9272032334592742\n",
      "Accuracy Dev:  0.9162856137882518\n",
      "Accuracy Test:  0.9251581166549543\n",
      "Weighted F1 Train:  0.9139051598905698\n",
      "Weighted F1 Dev:  0.9013350066111487\n",
      "Weighted F1 Test:  0.9123467976863688\n",
      "Macro F1 Train:  0.46161651290490496\n",
      "Macro F1 Dev:  0.4520082267407457\n",
      "Macro F1 Test:  0.463105918850385\n",
      "Micro F1 Train:  0.9272032334592742\n",
      "Micro F1 Dev:  0.9162856137882518\n",
      "Micro F1 Test:  0.9251581166549543\n",
      "Weighted Recall Train:  0.9272032334592742\n",
      "Weighted Recall Dev:  0.9162856137882518\n",
      "Weighted Recall Test:  0.9251581166549543\n",
      "Macro Recall Train:  0.43104435227057863\n",
      "Macro Recall Dev:  0.4245677153695266\n",
      "Macro Recall Test:  0.4336531687877619\n",
      "Micro Recall Train:  0.9272032334592742\n",
      "Micro Recall Dev:  0.9162856137882518\n",
      "Micro Recall Test:  0.9251581166549543\n",
      "Confusion Matrix Train: \n",
      "[[  601  1361     0]\n",
      " [  274 20504     0]\n",
      " [    0    22     0]]\n",
      "Confusion Matrix Dev: \n",
      "[[  79  193    0]\n",
      " [  43 2526    0]\n",
      " [   0    2    0]]\n",
      "Confusion Matrix Test: \n",
      "[[  79  171    0]\n",
      " [  39 2554    0]\n",
      " [   0    3    0]]\n"
     ]
    }
   ],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Transformer Better No PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, dev, test = load_sent_trans_better_no_pca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "35 fits failed out of a total of 140.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.91283719 0.91283719 0.91283719        nan 0.91283719\n",
      " 0.91283719 0.91283719        nan 0.91885588 0.9256215  0.92272192\n",
      "        nan 0.92935597 0.93023452 0.92918014        nan 0.92887272\n",
      " 0.92896061 0.92957567        nan 0.92553391 0.92645639 0.92751077\n",
      "        nan 0.92553395 0.92570968 0.92566569]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "grid_results = gridsearch.fit(train, train_labels)\n",
    "best_params = grid_results.best_params_\n",
    "logistic_reg = grid_results.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1.0, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logistic_reg = logistic_reg.fit(train, train_labels)\n",
    "save_model(logistic_reg, \"logistic_reg_sent_trans_best_no_pca.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = logistic_reg.predict(train)\n",
    "dev_preds =logistic_reg.predict(dev)\n",
    "test_preds = logistic_reg.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Train:  0.9352868816448466\n",
      "Accuracy Dev:  0.9240239183960605\n",
      "Accuracy Test:  0.9311314125087843\n",
      "Weighted F1 Train:  0.9261101311818531\n",
      "Weighted F1 Dev:  0.9136867360603871\n",
      "Weighted F1 Test:  0.9216696889708637\n",
      "Macro F1 Train:  0.49553253878259124\n",
      "Macro F1 Dev:  0.4839473214912968\n",
      "Macro F1 Test:  0.48895830301854454\n",
      "Micro F1 Train:  0.9352868816448465\n",
      "Micro F1 Dev:  0.9240239183960605\n",
      "Micro F1 Test:  0.9311314125087843\n",
      "Weighted Recall Train:  0.9352868816448466\n",
      "Weighted Recall Dev:  0.9240239183960605\n",
      "Weighted Recall Test:  0.9311314125087843\n",
      "Macro Recall Train:  0.46307423096784817\n",
      "Macro Recall Dev:  0.4548157137514406\n",
      "Macro Recall Test:  0.4587293996657668\n",
      "Micro Recall Train:  0.9352868816448466\n",
      "Micro Recall Dev:  0.9240239183960605\n",
      "Micro Recall Test:  0.9311314125087843\n",
      "Confusion Matrix Train: \n",
      "[[  790  1172     0]\n",
      " [  279 20499     0]\n",
      " [    0    22     0]]\n",
      "Confusion Matrix Dev: \n",
      "[[ 104  168    0]\n",
      " [  46 2523    0]\n",
      " [   0    2    0]]\n",
      "Confusion Matrix Test: \n",
      "[[  98  152    0]\n",
      " [  41 2552    0]\n",
      " [   0    3    0]]\n"
     ]
    }
   ],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Transformer Better PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, dev, test = load_sent_trans_better_pca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "35 fits failed out of a total of 140.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.91283719 0.91283719 0.91283719        nan 0.91283719\n",
      " 0.91283719 0.91283719        nan 0.92395212 0.92544577 0.92263408\n",
      "        nan 0.92860897 0.9294437  0.92882864        nan 0.92808196\n",
      " 0.92812585 0.92852129        nan 0.92768663 0.92724719 0.92777448\n",
      "        nan 0.92764264 0.9269836  0.92764267]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "grid_results = gridsearch.fit(train, train_labels)\n",
    "best_params = grid_results.best_params_\n",
    "logistic_reg = grid_results.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1.0, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logistic_reg = logistic_reg.fit(train, train_labels)\n",
    "save_model(logistic_reg, \"logistic_reg_sent_trans_best_pca.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = logistic_reg.predict(train)\n",
    "dev_preds =logistic_reg.predict(dev)\n",
    "test_preds = logistic_reg.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Train:  0.9336174325630436\n",
      "Accuracy Dev:  0.9236721772775237\n",
      "Accuracy Test:  0.9311314125087843\n",
      "Weighted F1 Train:  0.9240535983557454\n",
      "Weighted F1 Dev:  0.912960528756923\n",
      "Weighted F1 Test:  0.9212422930437894\n",
      "Macro F1 Train:  0.4904077199598218\n",
      "Macro F1 Dev:  0.48188597793477134\n",
      "Macro F1 Test:  0.4872493519552343\n",
      "Micro F1 Train:  0.9336174325630436\n",
      "Micro F1 Dev:  0.9236721772775237\n",
      "Micro F1 Test:  0.9311314125087843\n",
      "Weighted Recall Train:  0.9336174325630436\n",
      "Weighted Recall Dev:  0.9236721772775237\n",
      "Weighted Recall Test:  0.9311314125087843\n",
      "Macro Recall Train:  0.45861831041595097\n",
      "Macro Recall Dev:  0.45249448553263266\n",
      "Macro Recall Test:  0.4563198354544286\n",
      "Micro Recall Train:  0.9336174325630436\n",
      "Micro Recall Dev:  0.9236721772775237\n",
      "Micro Recall Test:  0.9311314125087843\n",
      "Confusion Matrix Train: \n",
      "[[  765  1197     0]\n",
      " [  292 20486     0]\n",
      " [    0    22     0]]\n",
      "Confusion Matrix Dev: \n",
      "[[ 102  170    0]\n",
      " [  45 2524    0]\n",
      " [   0    2    0]]\n",
      "Confusion Matrix Test: \n",
      "[[  96  154    0]\n",
      " [  39 2554    0]\n",
      " [   0    3    0]]\n"
     ]
    }
   ],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b8036f07cd5417c7187a91a95878ecc701a901071f70b01b87b4bc5de8f9f940"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
