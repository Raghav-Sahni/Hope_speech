{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from embeddings_loader import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_labels, dev_labels, test_labels = load_labels()\n",
    "train_augmented_labels, dev_augmented_labels, test_augmented_labels = load_augmented_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_replacement = {\n",
    "    'Hope_speech': 0,\n",
    "    'Non_hope_speech': 1,\n",
    "    'not-English': 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace labels with numbers\n",
    "train_labels = [label_replacement[label] for label in train_labels]\n",
    "dev_labels = [label_replacement[label] for label in dev_labels]\n",
    "test_labels = [label_replacement[label] for label in test_labels]\n",
    "train_augmented_labels = [label_replacement[label] for label in train_augmented_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_reg = LogisticRegression()\n",
    "grid = {\"penalty\" : ['l1', 'l2'], \"C\" : np.logspace(-3,3,7), \"solver\" : ['lbfgs', 'liblinear'], \"max_iter\":[1000]}\n",
    "gridsearch = GridSearchCV(logistic_reg, param_grid = grid, scoring = \"f1_micro\", n_jobs=os.cpu_count()//2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glove Twitter 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt25_train, gt25_dev, gt25_test = load_glove_twitter_25()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set all NaN values to 0\n",
    "gt25_train = np.nan_to_num(gt25_train)\n",
    "gt25_dev = np.nan_to_num(gt25_dev)\n",
    "gt25_test = np.nan_to_num(gt25_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "35 fits failed out of a total of 140.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.91261752 0.91283719 0.91283719        nan 0.91283719\n",
      " 0.91283718 0.91288112        nan 0.91283722 0.9117389  0.91283719\n",
      "        nan 0.91138747 0.91121174 0.9113435         nan 0.91121173\n",
      " 0.91107994 0.91112386        nan 0.91121173 0.91116781 0.91121173\n",
      "        nan 0.91121173 0.91116781 0.91121173]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "grid_results = gridsearch.fit(gt25_train, train_labels)\n",
    "best_params = grid_results.best_params_\n",
    "logistic_reg = grid_results.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.01, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logistic_reg = logistic_reg.fit(gt25_train, train_labels)\n",
    "save_model(logistic_reg, \"logistic_reg_gt25.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = logistic_reg.predict(gt25_train)\n",
    "dev_preds = logistic_reg.predict(gt25_dev)\n",
    "test_preds = logistic_reg.predict(gt25_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Train:  0.9128811176522273\n",
      "Accuracy Dev:  0.9036229335209286\n",
      "Accuracy Test:  0.9111033028812369\n",
      "Weighted F1 Train:  0.8713494955888584\n",
      "Weighted F1 Dev:  0.85787410059692\n",
      "Weighted F1 Test:  0.8687225094212346\n",
      "Macro F1 Train:  0.3184911585290693\n",
      "Macro F1 Dev:  0.31645725548164577\n",
      "Macro F1 Test:  0.31782803211374644\n",
      "Micro F1 Train:  0.9128811176522273\n",
      "Micro F1 Dev:  0.9036229335209286\n",
      "Micro F1 Test:  0.9111033028812369\n",
      "Weighted Recall Train:  0.9128811176522273\n",
      "Weighted Recall Dev:  0.9036229335209286\n",
      "Weighted Recall Test:  0.9111033028812369\n",
      "Macro Recall Train:  0.3335032279986408\n",
      "Macro Recall Dev:  0.3333333333333333\n",
      "Macro Recall Test:  0.3333333333333333\n",
      "Micro Recall Train:  0.9128811176522273\n",
      "Micro Recall Dev:  0.9036229335209286\n",
      "Micro Recall Test:  0.9111033028812369\n",
      "Confusion Matrix Train: \n",
      "[[    1  1961     0]\n",
      " [    0 20778     0]\n",
      " [    0    22     0]]\n",
      "Confusion Matrix Dev: \n",
      "[[   0  272    0]\n",
      " [   0 2569    0]\n",
      " [   0    2    0]]\n",
      "Confusion Matrix Test: \n",
      "[[   0  250    0]\n",
      " [   0 2593    0]\n",
      " [   0    3    0]]\n"
     ]
    }
   ],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FastText 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft300_train, ft300_dev, ft300_test = load_fasttext_300()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set all NaN values to 0\n",
    "ft300_train = np.nan_to_num(ft300_train)\n",
    "ft300_dev = np.nan_to_num(ft300_dev)\n",
    "ft300_test = np.nan_to_num(ft300_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "35 fits failed out of a total of 140.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.91283719 0.91283719 0.91283719        nan 0.91283719\n",
      " 0.91283719 0.91283719        nan 0.91283719 0.91283719 0.91283719\n",
      "        nan 0.913672   0.9139795  0.91375977        nan 0.91068463\n",
      " 0.91261765 0.91314482        nan 0.90954239 0.90993777 0.91024527\n",
      "        nan 0.90835616 0.90888346 0.9097181 ]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "grid_results = gridsearch.fit(ft300_train, train_labels)\n",
    "best_params = grid_results.best_params_\n",
    "logistic_reg = grid_results.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 100.0, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ft300_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Third Year\\5th Sem\\ML\\Project\\ML_Project\\Models\\Logistic_Regression.ipynb Cell 19\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Third%20Year/5th%20Sem/ML/Project/ML_Project/Models/Logistic_Regression.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m logistic_reg \u001b[39m=\u001b[39m logistic_reg\u001b[39m.\u001b[39mfit(ft300_train, train_labels)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Third%20Year/5th%20Sem/ML/Project/ML_Project/Models/Logistic_Regression.ipynb#X24sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m save_model(logistic_reg, \u001b[39m\"\u001b[39m\u001b[39mlogistic_reg_ft300.joblib\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ft300_train' is not defined"
     ]
    }
   ],
   "source": [
    "logistic_reg = logistic_reg.fit(ft300_train, train_labels)\n",
    "save_model(logistic_reg, \"logistic_reg_ft300.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = logistic_reg.predict(ft300_train)\n",
    "dev_preds = logistic_reg.predict(ft300_dev)\n",
    "test_preds = logistic_reg.predict(ft300_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Train:  0.9142869695105879\n",
      "Accuracy Dev:  0.9064368624692226\n",
      "Accuracy Test:  0.9125087842586086\n",
      "Weighted F1 Train:  0.8788590497232962\n",
      "Weighted F1 Dev:  0.8693550919504244\n",
      "Weighted F1 Test:  0.8752741881019258\n",
      "Macro F1 Train:  0.34563763231027994\n",
      "Macro F1 Dev:  0.3529130466769665\n",
      "Macro F1 Test:  0.3407610668900991\n",
      "Micro F1 Train:  0.9142869695105879\n",
      "Micro F1 Dev:  0.9064368624692226\n",
      "Micro F1 Test:  0.9125087842586086\n",
      "Weighted Recall Train:  0.9142869695105879\n",
      "Weighted Recall Dev:  0.9064368624692226\n",
      "Weighted Recall Test:  0.9125087842586086\n",
      "Macro Recall Train:  0.3470940162637715\n",
      "Macro Recall Dev:  0.35190315908379705\n",
      "Macro Recall Test:  0.34469057719501217\n",
      "Micro Recall Train:  0.9142869695105879\n",
      "Micro Recall Dev:  0.9064368624692226\n",
      "Micro Recall Test:  0.9125087842586086\n",
      "Confusion Matrix Train: \n",
      "[[   86  1876     0]\n",
      " [   53 20725     0]\n",
      " [    0    22     0]]\n",
      "Confusion Matrix Dev: \n",
      "[[  16  256    0]\n",
      " [   8 2561    0]\n",
      " [   0    2    0]]\n",
      "Confusion Matrix Test: \n",
      "[[   9  241    0]\n",
      " [   5 2588    0]\n",
      " [   0    3    0]]\n"
     ]
    }
   ],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v300_train, w2v300_dev, w2v300_test = load_word2vec_300()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set all NaN values to 0\n",
    "w2v300_train = np.nan_to_num(w2v300_train)\n",
    "w2v300_dev = np.nan_to_num(w2v300_dev)\n",
    "w2v300_test = np.nan_to_num(w2v300_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "35 fits failed out of a total of 140.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.91283719 0.91283719 0.91283719        nan 0.91283719\n",
      " 0.91283719 0.91283719        nan 0.91305684 0.91402345 0.91367192\n",
      "        nan 0.9116072  0.91204648 0.91239798        nan 0.91059676\n",
      " 0.91108    0.91094821        nan 0.90984987 0.9100256  0.9102892\n",
      "        nan 0.90901516 0.90875155 0.91015743]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "grid_results = gridsearch.fit(w2v300_train, train_labels)\n",
    "best_params = grid_results.best_params_\n",
    "logistic_reg = grid_results.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_reg = logistic_reg.fit(w2v300_train, train_labels)\n",
    "save_model(logistic_reg, \"logistic_reg_w2v300.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = logistic_reg.predict(w2v300_train)\n",
    "dev_preds = logistic_reg.predict(w2v300_dev)\n",
    "test_preds = logistic_reg.predict(w2v300_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Train:  0.914243036640014\n",
      "Accuracy Dev:  0.9064368624692226\n",
      "Accuracy Test:  0.9104005621925509\n",
      "Weighted F1 Train:  0.8791989825142942\n",
      "Weighted F1 Dev:  0.8699112143150298\n",
      "Weighted F1 Test:  0.8740860037544342\n",
      "Macro F1 Train:  0.3470623060519927\n",
      "Macro F1 Dev:  0.35490221977435915\n",
      "Macro F1 Test:  0.3398700047159173\n",
      "Micro F1 Train:  0.914243036640014\n",
      "Micro F1 Dev:  0.9064368624692226\n",
      "Micro F1 Test:  0.9104005621925509\n",
      "Weighted Recall Train:  0.914243036640014\n",
      "Weighted Recall Dev:  0.9064368624692226\n",
      "Weighted Recall Test:  0.9104005621925509\n",
      "Macro Recall Train:  0.3478472339352893\n",
      "Macro Recall Dev:  0.35299889710652654\n",
      "Macro Recall Test:  0.3439192698290268\n",
      "Micro Recall Train:  0.914243036640014\n",
      "Micro Recall Dev:  0.9064368624692226\n",
      "Micro Recall Test:  0.9104005621925509\n",
      "Confusion Matrix Train: \n",
      "[[   91  1871     0]\n",
      " [   59 20719     0]\n",
      " [    0    22     0]]\n",
      "Confusion Matrix Dev: \n",
      "[[  17  255    0]\n",
      " [   9 2560    0]\n",
      " [   0    2    0]]\n",
      "Confusion Matrix Test: \n",
      "[[   9  241    0]\n",
      " [  11 2582    0]\n",
      " [   0    3    0]]\n"
     ]
    }
   ],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF PCA (1000 Dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_pca_train, tfidf_pca_dev, tfidf_pca_test = load_tfidf_pca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "35 fits failed out of a total of 140.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.91283719 0.91283719 0.91283719        nan 0.91283719\n",
      " 0.91283719 0.91283719        nan 0.91516568 0.91534137 0.91318865\n",
      "        nan 0.9237325  0.92478701 0.92298575        nan 0.92421593\n",
      " 0.92491883 0.92597322        nan 0.92210709 0.92272217 0.92346903\n",
      "        nan 0.91991043 0.92087696 0.92144811]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "grid_results = gridsearch.fit(tfidf_pca_train, train_labels)\n",
    "best_params = grid_results.best_params_\n",
    "logistic_reg = grid_results.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10.0, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logistic_reg = logistic_reg.fit(tfidf_pca_train, train_labels)\n",
    "save_model(logistic_reg, \"logistic_reg_tfidf_pca.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = logistic_reg.predict(tfidf_pca_train)\n",
    "dev_preds = logistic_reg.predict(tfidf_pca_dev)\n",
    "test_preds = logistic_reg.predict(tfidf_pca_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Train:  0.9358140760917318\n",
      "Accuracy Dev:  0.9162856137882518\n",
      "Accuracy Test:  0.9226985242445538\n",
      "Weighted F1 Train:  0.9260862642946405\n",
      "Weighted F1 Dev:  0.9051578788710987\n",
      "Weighted F1 Test:  0.9116437521939569\n",
      "Macro F1 Train:  0.4944128742208025\n",
      "Macro F1 Dev:  0.466049692708707\n",
      "Macro F1 Test:  0.46496183555007087\n",
      "Micro F1 Train:  0.9358140760917318\n",
      "Micro F1 Dev:  0.9162856137882518\n",
      "Micro F1 Test:  0.9226985242445538\n",
      "Weighted Recall Train:  0.9358140760917318\n",
      "Weighted Recall Dev:  0.9162856137882518\n",
      "Weighted Recall Test:  0.9226985242445538\n",
      "Macro Recall Train:  0.4604974052674116\n",
      "Macro Recall Dev:  0.44100378571046944\n",
      "Macro Recall Test:  0.4387772207224579\n",
      "Micro Recall Train:  0.9358140760917318\n",
      "Micro Recall Dev:  0.9162856137882518\n",
      "Micro Recall Test:  0.9226985242445538\n",
      "Confusion Matrix Train: \n",
      "[[  772  1190     0]\n",
      " [  249 20529     0]\n",
      " [    0    22     0]]\n",
      "Confusion Matrix Dev: \n",
      "[[  94  178    0]\n",
      " [  58 2511    0]\n",
      " [   0    2    0]]\n",
      "Confusion Matrix Test: \n",
      "[[  84  166    0]\n",
      " [  51 2542    0]\n",
      " [   0    3    0]]\n"
     ]
    }
   ],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seentence Transformer Faster No PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, dev, test = load_sent_trans_fast_no_pca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "35 fits failed out of a total of 140.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.91283719 0.91283719 0.91283719        nan 0.91283719\n",
      " 0.91283719 0.91283719        nan 0.91854842 0.92417184 0.92100861\n",
      "        nan 0.92562145 0.92548971 0.92575326        nan 0.92452321\n",
      " 0.92478678 0.9253579         nan 0.92461111 0.92447931 0.92461107\n",
      "        nan 0.92469899 0.92439146 0.92465505]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "grid_results = gridsearch.fit(train, train_labels)\n",
    "best_params = grid_results.best_params_\n",
    "logistic_reg = grid_results.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1.0, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logistic_reg = logistic_reg.fit(train, train_labels)\n",
    "save_model(logistic_reg, \"logistic_reg_sent_trans_fast_no_pca.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = logistic_reg.predict(train)\n",
    "dev_preds = logistic_reg.predict(dev)\n",
    "test_preds = logistic_reg.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Train:  0.9288726825410772\n",
      "Accuracy Dev:  0.9176925782623989\n",
      "Accuracy Test:  0.9248067463106114\n",
      "Weighted F1 Train:  0.9153117608065434\n",
      "Weighted F1 Dev:  0.9013103392248377\n",
      "Weighted F1 Test:  0.9112775168450953\n",
      "Macro F1 Train:  0.4641122403976934\n",
      "Macro F1 Dev:  0.44951195604016525\n",
      "Macro F1 Test:  0.45951751150945497\n",
      "Micro F1 Train:  0.9288726825410772\n",
      "Micro F1 Dev:  0.9176925782623989\n",
      "Micro F1 Test:  0.9248067463106114\n",
      "Weighted Recall Train:  0.9288726825410772\n",
      "Weighted Recall Dev:  0.9176925782623989\n",
      "Weighted Recall Test:  0.9248067463106114\n",
      "Macro Recall Train:  0.4319616755313121\n",
      "Macro Recall Dev:  0.4207037719720041\n",
      "Macro Recall Test:  0.4299102712430904\n",
      "Micro Recall Train:  0.9288726825410772\n",
      "Micro Recall Dev:  0.9176925782623989\n",
      "Micro Recall Test:  0.9248067463106114\n",
      "Confusion Matrix Train: \n",
      "[[  603  1359     0]\n",
      " [  238 20540     0]\n",
      " [    0    22     0]]\n",
      "Confusion Matrix Dev: \n",
      "[[  75  197    0]\n",
      " [  35 2534    0]\n",
      " [   0    2    0]]\n",
      "Confusion Matrix Test: \n",
      "[[  76  174    0]\n",
      " [  37 2556    0]\n",
      " [   0    3    0]]\n"
     ]
    }
   ],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Transformer Faster PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, dev, test = load_sent_trans_fast_pca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "35 fits failed out of a total of 140.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.91283719 0.91283719 0.91283719        nan 0.91283719\n",
      " 0.91283719 0.91283719        nan 0.9224585  0.92430363 0.92092078\n",
      "        nan 0.92509426 0.92478672 0.9249625         nan 0.92456711\n",
      " 0.92469889 0.92469884        nan 0.92465498 0.92465495 0.92461103\n",
      "        nan 0.92456711 0.92434744 0.92465498]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "grid_results = gridsearch.fit(train, train_labels)\n",
    "best_params = grid_results.best_params_\n",
    "logistic_reg = grid_results.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1.0, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logistic_reg = logistic_reg.fit(train, train_labels)\n",
    "save_model(logistic_reg, \"logistic_reg_sent_trans_fast_pca.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = logistic_reg.predict(train)\n",
    "dev_preds =logistic_reg.predict(dev)\n",
    "test_preds = logistic_reg.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Train:  0.9272032334592742\n",
      "Accuracy Dev:  0.9162856137882518\n",
      "Accuracy Test:  0.9251581166549543\n",
      "Weighted F1 Train:  0.9139051598905698\n",
      "Weighted F1 Dev:  0.9013350066111487\n",
      "Weighted F1 Test:  0.9123467976863688\n",
      "Macro F1 Train:  0.46161651290490496\n",
      "Macro F1 Dev:  0.4520082267407457\n",
      "Macro F1 Test:  0.463105918850385\n",
      "Micro F1 Train:  0.9272032334592742\n",
      "Micro F1 Dev:  0.9162856137882518\n",
      "Micro F1 Test:  0.9251581166549543\n",
      "Weighted Recall Train:  0.9272032334592742\n",
      "Weighted Recall Dev:  0.9162856137882518\n",
      "Weighted Recall Test:  0.9251581166549543\n",
      "Macro Recall Train:  0.43104435227057863\n",
      "Macro Recall Dev:  0.4245677153695266\n",
      "Macro Recall Test:  0.4336531687877619\n",
      "Micro Recall Train:  0.9272032334592742\n",
      "Micro Recall Dev:  0.9162856137882518\n",
      "Micro Recall Test:  0.9251581166549543\n",
      "Confusion Matrix Train: \n",
      "[[  601  1361     0]\n",
      " [  274 20504     0]\n",
      " [    0    22     0]]\n",
      "Confusion Matrix Dev: \n",
      "[[  79  193    0]\n",
      " [  43 2526    0]\n",
      " [   0    2    0]]\n",
      "Confusion Matrix Test: \n",
      "[[  79  171    0]\n",
      " [  39 2554    0]\n",
      " [   0    3    0]]\n"
     ]
    }
   ],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Transformer Better No PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, dev, test = load_sent_trans_better_no_pca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "35 fits failed out of a total of 140.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.91283719 0.91283719 0.91283719        nan 0.91283719\n",
      " 0.91283719 0.91283719        nan 0.91885588 0.9256215  0.92272192\n",
      "        nan 0.92935597 0.93023452 0.92918014        nan 0.92887272\n",
      " 0.92896061 0.92957567        nan 0.92553391 0.92645639 0.92751077\n",
      "        nan 0.92553395 0.92570968 0.92566569]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "grid_results = gridsearch.fit(train, train_labels)\n",
    "best_params = grid_results.best_params_\n",
    "logistic_reg = grid_results.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1.0, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logistic_reg = logistic_reg.fit(train, train_labels)\n",
    "save_model(logistic_reg, \"logistic_reg_sent_trans_best_no_pca.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = logistic_reg.predict(train)\n",
    "dev_preds =logistic_reg.predict(dev)\n",
    "test_preds = logistic_reg.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Train:  0.9352868816448466\n",
      "Accuracy Dev:  0.9240239183960605\n",
      "Accuracy Test:  0.9311314125087843\n",
      "Weighted F1 Train:  0.9261101311818531\n",
      "Weighted F1 Dev:  0.9136867360603871\n",
      "Weighted F1 Test:  0.9216696889708637\n",
      "Macro F1 Train:  0.49553253878259124\n",
      "Macro F1 Dev:  0.4839473214912968\n",
      "Macro F1 Test:  0.48895830301854454\n",
      "Micro F1 Train:  0.9352868816448465\n",
      "Micro F1 Dev:  0.9240239183960605\n",
      "Micro F1 Test:  0.9311314125087843\n",
      "Weighted Recall Train:  0.9352868816448466\n",
      "Weighted Recall Dev:  0.9240239183960605\n",
      "Weighted Recall Test:  0.9311314125087843\n",
      "Macro Recall Train:  0.46307423096784817\n",
      "Macro Recall Dev:  0.4548157137514406\n",
      "Macro Recall Test:  0.4587293996657668\n",
      "Micro Recall Train:  0.9352868816448466\n",
      "Micro Recall Dev:  0.9240239183960605\n",
      "Micro Recall Test:  0.9311314125087843\n",
      "Confusion Matrix Train: \n",
      "[[  790  1172     0]\n",
      " [  279 20499     0]\n",
      " [    0    22     0]]\n",
      "Confusion Matrix Dev: \n",
      "[[ 104  168    0]\n",
      " [  46 2523    0]\n",
      " [   0    2    0]]\n",
      "Confusion Matrix Test: \n",
      "[[  98  152    0]\n",
      " [  41 2552    0]\n",
      " [   0    3    0]]\n"
     ]
    }
   ],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Transformer Better PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, dev, test = load_sent_trans_better_pca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "35 fits failed out of a total of 140.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.91283719 0.91283719 0.91283719        nan 0.91283719\n",
      " 0.91283719 0.91283719        nan 0.92395212 0.92544577 0.92263408\n",
      "        nan 0.92860897 0.9294437  0.92882864        nan 0.92808196\n",
      " 0.92812585 0.92852129        nan 0.92768663 0.92724719 0.92777448\n",
      "        nan 0.92764264 0.9269836  0.92764267]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "grid_results = gridsearch.fit(train, train_labels)\n",
    "best_params = grid_results.best_params_\n",
    "logistic_reg = grid_results.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1.0, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logistic_reg = logistic_reg.fit(train, train_labels)\n",
    "save_model(logistic_reg, \"logistic_reg_sent_trans_best_pca.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = logistic_reg.predict(train)\n",
    "dev_preds =logistic_reg.predict(dev)\n",
    "test_preds = logistic_reg.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Train:  0.9336174325630436\n",
      "Accuracy Dev:  0.9236721772775237\n",
      "Accuracy Test:  0.9311314125087843\n",
      "Weighted F1 Train:  0.9240535983557454\n",
      "Weighted F1 Dev:  0.912960528756923\n",
      "Weighted F1 Test:  0.9212422930437894\n",
      "Macro F1 Train:  0.4904077199598218\n",
      "Macro F1 Dev:  0.48188597793477134\n",
      "Macro F1 Test:  0.4872493519552343\n",
      "Micro F1 Train:  0.9336174325630436\n",
      "Micro F1 Dev:  0.9236721772775237\n",
      "Micro F1 Test:  0.9311314125087843\n",
      "Weighted Recall Train:  0.9336174325630436\n",
      "Weighted Recall Dev:  0.9236721772775237\n",
      "Weighted Recall Test:  0.9311314125087843\n",
      "Macro Recall Train:  0.45861831041595097\n",
      "Macro Recall Dev:  0.45249448553263266\n",
      "Macro Recall Test:  0.4563198354544286\n",
      "Micro Recall Train:  0.9336174325630436\n",
      "Micro Recall Dev:  0.9236721772775237\n",
      "Micro Recall Test:  0.9311314125087843\n",
      "Confusion Matrix Train: \n",
      "[[  765  1197     0]\n",
      " [  292 20486     0]\n",
      " [    0    22     0]]\n",
      "Confusion Matrix Dev: \n",
      "[[ 102  170    0]\n",
      " [  45 2524    0]\n",
      " [   0    2    0]]\n",
      "Confusion Matrix Test: \n",
      "[[  96  154    0]\n",
      " [  39 2554    0]\n",
      " [   0    3    0]]\n"
     ]
    }
   ],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmented Data Sentence Transformer Better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_aug, dev, test = load_sent_trans_augmented_no_pca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "35 fits failed out of a total of 140.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.50922561 0.80527113 0.79543192        nan 0.75855293\n",
      " 0.83330189 0.82485498        nan 0.84493387 0.85658979 0.85102149\n",
      "        nan 0.87169025 0.87128912 0.86833981        nan 0.87574834\n",
      " 0.87629107 0.87605517        nan 0.87588988 0.87586627 0.87652695\n",
      "        nan 0.87551236 0.87544157 0.8758191 ]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "grid_results = gridsearch.fit(train_aug, train_augmented_labels)\n",
    "best_params = grid_results.best_params_\n",
    "logistic_reg = grid_results.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 100.0, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logistic_reg = logistic_reg.fit(train_aug, train_augmented_labels)\n",
    "save_model(logistic_reg, \"logistic_reg_sent_trans_augmented_no_pca.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = logistic_reg.predict(train_aug)\n",
    "dev_preds = logistic_reg.predict(dev)\n",
    "test_preds = logistic_reg.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Train:  0.8849747534330612\n",
      "Accuracy Dev:  0.0\n",
      "Accuracy Test:  0.0\n",
      "Weighted F1 Train:  0.8847406230259393\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Mix of label input types (string and number)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\Third Year\\5th Sem\\ML\\Project\\ML_Project\\Models\\Logistic_Regression.ipynb Cell 72\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Third%20Year/5th%20Sem/ML/Project/ML_Project/Models/Logistic_Regression.ipynb#Y131sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m computeAllScores(train_preds, dev_preds, test_preds, aug\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32md:\\Third Year\\5th Sem\\ML\\Project\\ML_Project\\Models\\utils.py:114\u001b[0m, in \u001b[0;36mcomputeAllScores\u001b[1;34m(y_pred_train, y_pred_dev, y_pred_test, aug, two_class)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAccuracy Test: \u001b[39m\u001b[39m\"\u001b[39m, accuracy_score(test_l, y_pred_test))\n\u001b[0;32m    113\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mWeighted F1 Train: \u001b[39m\u001b[39m\"\u001b[39m, f1_score(train_l, y_pred_train, average\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mweighted\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m--> 114\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mWeighted F1 Dev: \u001b[39m\u001b[39m\"\u001b[39m, f1_score(dev_l, y_pred_dev, average\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mweighted\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[0;32m    115\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mWeighted F1 Test: \u001b[39m\u001b[39m\"\u001b[39m, f1_score(test_l, y_pred_test, average\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mweighted\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m    116\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mMacro F1 Train: \u001b[39m\u001b[39m\"\u001b[39m, f1_score(train_l, y_pred_train, average\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmacro\u001b[39m\u001b[39m\"\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1123\u001b[0m, in \u001b[0;36mf1_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m    992\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mf1_score\u001b[39m(\n\u001b[0;32m    993\u001b[0m     y_true,\n\u001b[0;32m    994\u001b[0m     y_pred,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1000\u001b[0m     zero_division\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwarn\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1001\u001b[0m ):\n\u001b[0;32m   1002\u001b[0m     \u001b[39m\"\"\"Compute the F1 score, also known as balanced F-score or F-measure.\u001b[39;00m\n\u001b[0;32m   1003\u001b[0m \n\u001b[0;32m   1004\u001b[0m \u001b[39m    The F1 score can be interpreted as a harmonic mean of the precision and\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1121\u001b[0m \u001b[39m    modified with ``zero_division``.\u001b[39;00m\n\u001b[0;32m   1122\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1123\u001b[0m     \u001b[39mreturn\u001b[39;00m fbeta_score(\n\u001b[0;32m   1124\u001b[0m         y_true,\n\u001b[0;32m   1125\u001b[0m         y_pred,\n\u001b[0;32m   1126\u001b[0m         beta\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m   1127\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[0;32m   1128\u001b[0m         pos_label\u001b[39m=\u001b[39;49mpos_label,\n\u001b[0;32m   1129\u001b[0m         average\u001b[39m=\u001b[39;49maverage,\n\u001b[0;32m   1130\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1131\u001b[0m         zero_division\u001b[39m=\u001b[39;49mzero_division,\n\u001b[0;32m   1132\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1261\u001b[0m, in \u001b[0;36mfbeta_score\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1135\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfbeta_score\u001b[39m(\n\u001b[0;32m   1136\u001b[0m     y_true,\n\u001b[0;32m   1137\u001b[0m     y_pred,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     zero_division\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwarn\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1145\u001b[0m ):\n\u001b[0;32m   1146\u001b[0m     \u001b[39m\"\"\"Compute the F-beta score.\u001b[39;00m\n\u001b[0;32m   1147\u001b[0m \n\u001b[0;32m   1148\u001b[0m \u001b[39m    The F-beta score is the weighted harmonic mean of precision and recall,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1258\u001b[0m \u001b[39m    array([0.71..., 0.        , 0.        ])\u001b[39;00m\n\u001b[0;32m   1259\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1261\u001b[0m     _, _, f, _ \u001b[39m=\u001b[39m precision_recall_fscore_support(\n\u001b[0;32m   1262\u001b[0m         y_true,\n\u001b[0;32m   1263\u001b[0m         y_pred,\n\u001b[0;32m   1264\u001b[0m         beta\u001b[39m=\u001b[39;49mbeta,\n\u001b[0;32m   1265\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[0;32m   1266\u001b[0m         pos_label\u001b[39m=\u001b[39;49mpos_label,\n\u001b[0;32m   1267\u001b[0m         average\u001b[39m=\u001b[39;49maverage,\n\u001b[0;32m   1268\u001b[0m         warn_for\u001b[39m=\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mf-score\u001b[39;49m\u001b[39m\"\u001b[39;49m,),\n\u001b[0;32m   1269\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1270\u001b[0m         zero_division\u001b[39m=\u001b[39;49mzero_division,\n\u001b[0;32m   1271\u001b[0m     )\n\u001b[0;32m   1272\u001b[0m     \u001b[39mreturn\u001b[39;00m f\n",
      "File \u001b[1;32mc:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1544\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1542\u001b[0m \u001b[39mif\u001b[39;00m beta \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1543\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mbeta should be >=0 in the F-beta score\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1544\u001b[0m labels \u001b[39m=\u001b[39m _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n\u001b[0;32m   1546\u001b[0m \u001b[39m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[0;32m   1547\u001b[0m samplewise \u001b[39m=\u001b[39m average \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msamples\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1351\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1348\u001b[0m y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[0;32m   1349\u001b[0m \u001b[39m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[39;00m\n\u001b[0;32m   1350\u001b[0m \u001b[39m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[39;00m\n\u001b[1;32m-> 1351\u001b[0m present_labels \u001b[39m=\u001b[39m unique_labels(y_true, y_pred)\u001b[39m.\u001b[39mtolist()\n\u001b[0;32m   1352\u001b[0m \u001b[39mif\u001b[39;00m average \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m   1353\u001b[0m     \u001b[39mif\u001b[39;00m y_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\diksh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\multiclass.py:107\u001b[0m, in \u001b[0;36munique_labels\u001b[1;34m(*ys)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[39m# Check that we don't mix string type with number type\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mset\u001b[39m(\u001b[39misinstance\u001b[39m(label, \u001b[39mstr\u001b[39m) \u001b[39mfor\u001b[39;00m label \u001b[39min\u001b[39;00m ys_labels)) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 107\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mMix of label input types (string and number)\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    109\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray(\u001b[39msorted\u001b[39m(ys_labels))\n",
      "\u001b[1;31mValueError\u001b[0m: Mix of label input types (string and number)"
     ]
    }
   ],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds, aug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b8036f07cd5417c7187a91a95878ecc701a901071f70b01b87b4bc5de8f9f940"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
