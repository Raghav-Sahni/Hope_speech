{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from embeddings_loader import *\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels, dev_labels, test_labels = load_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeAllScores(y_pred_train, y_pred_dev, y_pred_test):\n",
    "    print(\"Accuracy Train: \", accuracy_score(train_labels, y_pred_train))\n",
    "    print(\"Accuracy Dev: \", accuracy_score(dev_labels, y_pred_dev))\n",
    "    print(\"Accuracy Test: \", accuracy_score(test_labels, y_pred_test))\n",
    "    print(\"F1 Train: \", f1_score(train_labels, y_pred_train, average='macro'))\n",
    "    print(\"F1 Dev: \", f1_score(dev_labels, y_pred_dev, average='macro'))\n",
    "    print(\"F1 Test: \", f1_score(test_labels, y_pred_test, average='macro'))\n",
    "    print(\"Precision Train: \", precision_score(train_labels, y_pred_train, average='macro'))\n",
    "    print(\"Precision Dev: \", precision_score(dev_labels, y_pred_dev, average='macro'))\n",
    "    print(\"Precision Test: \", precision_score(test_labels, y_pred_test, average='macro'))\n",
    "    print(\"Recall Train: \", recall_score(train_labels, y_pred_train, average='macro'))\n",
    "    print(\"Recall Dev: \", recall_score(dev_labels, y_pred_dev, average='macro'))\n",
    "    print(\"Recall Test: \", recall_score(test_labels, y_pred_test, average='macro'))\n",
    "    # Confusion Matrix\n",
    "    print(\"Confusion Matrix Train: \")\n",
    "    print(confusion_matrix(train_labels, y_pred_train))\n",
    "    print(\"Confusion Matrix Dev: \")\n",
    "    print(confusion_matrix(dev_labels, y_pred_dev))\n",
    "    print(\"Confusion Matrix Test: \")\n",
    "    print(confusion_matrix(test_labels, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_replacement = {\n",
    "    'Hope_speech': 0,\n",
    "    'Non_hope_speech': 1,\n",
    "    'not-English': 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace labels with numbers\n",
    "train_labels = [label_replacement[label] for label in train_labels]\n",
    "dev_labels = [label_replacement[label] for label in dev_labels]\n",
    "test_labels = [label_replacement[label] for label in test_labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glove Twitter 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt25_train, gt25_dev, gt25_test = load_glove_twitter_25()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set all NaN values to 0\n",
    "gt25_train = np.nan_to_num(gt25_train)\n",
    "gt25_dev = np.nan_to_num(gt25_dev)\n",
    "gt25_test = np.nan_to_num(gt25_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_medoids = KMedoids(n_clusters=3, random_state=0).fit(gt25_train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = k_medoids.predict(gt25_train)\n",
    "dev_preds = k_medoids.predict(gt25_dev)\n",
    "test_preds = k_medoids.predict(gt25_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Train:  0.39056321940075567\n",
      "Accuracy Dev:  0.3939500527611678\n",
      "Accuracy Test:  0.3882642304989459\n",
      "F1 Train:  0.23299111756158597\n",
      "F1 Dev:  0.24149580109249755\n",
      "F1 Test:  0.2308150733779275\n",
      "Precision Train:  0.34398741977465647\n",
      "Precision Dev:  0.34627506487379095\n",
      "Precision Test:  0.34233578200791315\n",
      "Recall Train:  0.2999336290008057\n",
      "Recall Dev:  0.2527047603782657\n",
      "Recall Test:  0.3445951064832669\n",
      "Confusion Matrix Train: \n",
      "[[ 629  488  845]\n",
      " [6474 8257 6047]\n",
      " [   6   12    4]]\n",
      "Confusion Matrix Dev: \n",
      "[[  98   75   99]\n",
      " [ 802 1022  745]\n",
      " [   0    2    0]]\n",
      "Confusion Matrix Test: \n",
      "[[  76   63  111]\n",
      " [ 823 1028  742]\n",
      " [   1    1    1]]\n"
     ]
    }
   ],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FastText 300 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft300_train, ft300_dev, ft300_test = load_fasttext_300()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set all NaN values to 0\n",
    "ft300_train = np.nan_to_num(ft300_train)\n",
    "ft300_dev = np.nan_to_num(ft300_dev)\n",
    "ft300_test = np.nan_to_num(ft300_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_medoids = KMedoids(n_clusters=3, random_state=0).fit(ft300_train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = k_medoids.predict(ft300_train)\n",
    "dev_preds = k_medoids.predict(ft300_dev)\n",
    "test_preds = k_medoids.predict(ft300_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Train:  0.30151129074773747\n",
      "Accuracy Dev:  0.3119943721421034\n",
      "Accuracy Test:  0.3021784961349262\n",
      "F1 Train:  0.18952357012854415\n",
      "F1 Dev:  0.19813893483270875\n",
      "F1 Test:  0.19204232944421282\n",
      "Precision Train:  0.32599741864358023\n",
      "Precision Dev:  0.33029516357735705\n",
      "Precision Test:  0.3300046219375368\n",
      "Recall Train:  0.28628109207736036\n",
      "Recall Dev:  0.40982844091315\n",
      "Recall Test:  0.2527183442601877\n",
      "Confusion Matrix Train: \n",
      "[[  850   651   461]\n",
      " [10313  6010  4455]\n",
      " [   12     7     3]]\n",
      "Confusion Matrix Dev: \n",
      "[[ 117   80   75]\n",
      " [1267  769  533]\n",
      " [   0    1    1]]\n",
      "Confusion Matrix Test: \n",
      "[[ 118   75   57]\n",
      " [1303  742  548]\n",
      " [   2    1    0]]\n"
     ]
    }
   ],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v300_train, w2v300_dev, w2v300_test = load_word2vec_300()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set all NaN values to 0\n",
    "w2v300_train = np.nan_to_num(w2v300_train)\n",
    "w2v300_dev = np.nan_to_num(w2v300_dev)\n",
    "w2v300_test = np.nan_to_num(w2v300_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_medoids = KMedoids(n_clusters=3, random_state=0).fit(w2v300_train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = k_medoids.predict(w2v300_train)\n",
    "dev_preds = k_medoids.predict(w2v300_dev)\n",
    "test_preds = k_medoids.predict(w2v300_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Train:  0.3707494947719884\n",
      "Accuracy Dev:  0.38199085473091804\n",
      "Accuracy Test:  0.3713984539704849\n",
      "F1 Train:  0.23889330096627073\n",
      "F1 Dev:  0.2492302440397095\n",
      "F1 Test:  0.23993587762796267\n",
      "Precision Train:  0.35736725425615096\n",
      "Precision Dev:  0.3628587705486155\n",
      "Precision Test:  0.3609947692708624\n",
      "Recall Train:  0.35835533026148364\n",
      "Recall Dev:  0.442223551545959\n",
      "Recall Test:  0.2659951150533488\n",
      "Confusion Matrix Train: \n",
      "[[ 859  374  729]\n",
      " [6313 7574 6891]\n",
      " [   5   11    6]]\n",
      "Confusion Matrix Dev: \n",
      "[[123  47 102]\n",
      " [788 962 819]\n",
      " [  0   1   1]]\n",
      "Confusion Matrix Test: \n",
      "[[108  36 106]\n",
      " [780 949 864]\n",
      " [  1   2   0]]\n"
     ]
    }
   ],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF PCA (1000 Dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_pca_train, tfidf_pca_dev, tfidf_pca_test = load_tfidf_pca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_medoids = KMedoids(n_clusters=3, random_state=0).fit(tfidf_pca_train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = k_medoids.predict(tfidf_pca_train)\n",
    "dev_preds = k_medoids.predict(tfidf_pca_dev)\n",
    "test_preds = k_medoids.predict(tfidf_pca_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Train:  0.08619629206572357\n",
      "Accuracy Dev:  0.09567358424199789\n",
      "Accuracy Test:  0.08784258608573436\n",
      "F1 Train:  0.05290406083158065\n",
      "F1 Dev:  0.05821294810058855\n",
      "F1 Test:  0.053832902670111975\n",
      "Precision Train:  0.028732097355241192\n",
      "Precision Dev:  0.03189119474733263\n",
      "Precision Test:  0.02928086202857812\n",
      "Recall Train:  0.3333333333333333\n",
      "Recall Dev:  0.3333333333333333\n",
      "Recall Test:  0.3333333333333333\n",
      "Confusion Matrix Train: \n",
      "[[ 1962     0     0]\n",
      " [20778     0     0]\n",
      " [   22     0     0]]\n",
      "Confusion Matrix Dev: \n",
      "[[ 272    0    0]\n",
      " [2569    0    0]\n",
      " [   2    0    0]]\n",
      "Confusion Matrix Test: \n",
      "[[ 250    0    0]\n",
      " [2593    0    0]\n",
      " [   3    0    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a5a87ee616be0254e3f1af9223138e3faeac65b2c9d91bc22a9fc5a4a8bd8eb0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
