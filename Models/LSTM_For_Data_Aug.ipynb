{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from utils import *\n",
    "\n",
    "# helps in text preprocessing\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# helps in LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = os.path.join(os.path.abspath(os.path.join(os.getcwd(), os.pardir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_train = pd.read_csv(os.path.join(parent_dir, 'Data\\AugmentedData\\english_train_augmented.csv'))\n",
    "df_dev = pd.read_csv(os.path.join(parent_dir, 'Data\\PreprocessedData\\english_dev_preprocess.csv'))\n",
    "df_test = pd.read_csv(os.path.join(parent_dir, 'Data\\PreprocessedData\\english_test_preprocess.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[['augmented_text', 'label']]\n",
    "df_dev = df_dev[['preprocessed_text', 'label']]\n",
    "df_test = df_test[['preprocessed_text', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_replacement = {\n",
    "    'Hope_speech': 0,\n",
    "    'Non_hope_speech': 1,\n",
    "    'not-English': 2,\n",
    "}\n",
    "\n",
    "df_train['label'] = df_train['label'].replace(label_replacement)\n",
    "df_test['label'] = df_test['label'].replace(label_replacement)\n",
    "df_dev['label'] = df_dev['label'].replace(label_replacement)\n",
    "\n",
    "# Drop rows with label 2\n",
    "df_train = df_train[df_train['label'] != 2]\n",
    "df_test = df_test[df_test['label'] != 2]\n",
    "df_dev = df_dev[df_dev['label'] != 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = df_train['augmented_text'].to_numpy(), df_train['label'].to_numpy()\n",
    "X_dev, y_dev = df_dev['preprocessed_text'].to_numpy(), df_dev['label'].to_numpy()\n",
    "X_test, y_test = df_test['preprocessed_text'].to_numpy(), df_test['label'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Tokenizer()\n",
    "t.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_train = t.texts_to_sequences(X_train)\n",
    "encoded_dev = t.texts_to_sequences(X_dev)\n",
    "encoded_test = t.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 8\n",
    "padded_train = pad_sequences(encoded_train, maxlen=max_length, padding='post')\n",
    "padded_dev = pad_sequences(encoded_dev, maxlen=max_length, padding='post')\n",
    "padded_test = pad_sequences(encoded_test, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 8, 24)             521064    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 24)                4704      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 25        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 525,793\n",
      "Trainable params: 525,793\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(t.word_index) + 1\n",
    "\n",
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 24, input_length=max_length))\n",
    "model.add(LSTM(24, return_sequences=False))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# summarize the model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1324/1324 [==============================] - 9s 5ms/step - loss: 0.4692 - accuracy: 0.7725 - val_loss: 0.4436 - val_accuracy: 0.7951\n",
      "Epoch 2/100\n",
      "1324/1324 [==============================] - 8s 6ms/step - loss: 0.3518 - accuracy: 0.8467 - val_loss: 0.4261 - val_accuracy: 0.8054\n",
      "Epoch 3/100\n",
      "1324/1324 [==============================] - 8s 6ms/step - loss: 0.3111 - accuracy: 0.8681 - val_loss: 0.3790 - val_accuracy: 0.8381\n",
      "Epoch 4/100\n",
      "1324/1324 [==============================] - 8s 6ms/step - loss: 0.2781 - accuracy: 0.8842 - val_loss: 0.3726 - val_accuracy: 0.8441\n",
      "Epoch 5/100\n",
      "1324/1324 [==============================] - 7s 5ms/step - loss: 0.2540 - accuracy: 0.8960 - val_loss: 0.3884 - val_accuracy: 0.8342\n",
      "Epoch 6/100\n",
      "1324/1324 [==============================] - 6s 5ms/step - loss: 0.2365 - accuracy: 0.9034 - val_loss: 0.3640 - val_accuracy: 0.8546\n",
      "Epoch 7/100\n",
      "1324/1324 [==============================] - 6s 5ms/step - loss: 0.2201 - accuracy: 0.9121 - val_loss: 0.4216 - val_accuracy: 0.8258\n",
      "Epoch 8/100\n",
      "1324/1324 [==============================] - 7s 5ms/step - loss: 0.2037 - accuracy: 0.9208 - val_loss: 0.4187 - val_accuracy: 0.8310\n",
      "Epoch 9/100\n",
      "1324/1324 [==============================] - 6s 4ms/step - loss: 0.1890 - accuracy: 0.9261 - val_loss: 0.4201 - val_accuracy: 0.8339\n",
      "Epoch 9: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20070405700>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3)\n",
    "\n",
    "# fit the model\n",
    "model.fit(\n",
    "    x=padded_train,\n",
    "    y=y_train,\n",
    "    epochs=100,\n",
    "    validation_data=(padded_dev, y_dev), verbose=1,\n",
    "    callbacks=[early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1324/1324 [==============================] - 2s 2ms/step\n",
      "89/89 [==============================] - 0s 2ms/step\n",
      "89/89 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "train_preds = model.predict(padded_train)\n",
    "dev_preds = model.predict(padded_dev)\n",
    "test_preds = model.predict(padded_test)\n",
    "\n",
    "train_preds = np.where(train_preds > 0.5, 1, 0)\n",
    "dev_preds = np.where(dev_preds > 0.5, 1, 0)\n",
    "test_preds = np.where(test_preds > 0.5, 1, 0)\n",
    "\n",
    "train_preds = train_preds.flatten()\n",
    "dev_preds = dev_preds.flatten()\n",
    "test_preds = test_preds.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Train:  0.9340415486307838\n",
      "Accuracy Dev:  0.833861316437874\n",
      "Accuracy Test:  0.8304607808652832\n",
      "Weighted F1 Train:  0.9339944893217119\n",
      "Weighted F1 Dev:  0.8538250329701035\n",
      "Weighted F1 Test:  0.854308848966864\n",
      "Macro F1 Train:  0.9339470761832485\n",
      "Macro F1 Dev:  0.6415256955880152\n",
      "Macro F1 Test:  0.6290023023458804\n",
      "Micro F1 Train:  0.9340415486307838\n",
      "Micro F1 Dev:  0.833861316437874\n",
      "Micro F1 Test:  0.8304607808652832\n",
      "Weighted Recall Train:  0.9340415486307838\n",
      "Weighted Recall Dev:  0.833861316437874\n",
      "Weighted Recall Test:  0.8304607808652832\n",
      "Macro Recall Train:  0.9336600914447455\n",
      "Macro Recall Dev:  0.6977537609049069\n",
      "Macro Recall Test:  0.6956182028538372\n",
      "Micro Recall Train:  0.9340415486307838\n",
      "Micro Recall Dev:  0.833861316437874\n",
      "Micro Recall Test:  0.8304607808652832\n",
      "Confusion Matrix Train: \n",
      "[[20584   998]\n",
      " [ 1796 18982]]\n",
      "Confusion Matrix Dev: \n",
      "[[ 144  128]\n",
      " [ 344 2225]]\n",
      "Confusion Matrix Test: \n",
      "[[ 133  117]\n",
      " [ 365 2228]]\n"
     ]
    }
   ],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a5a87ee616be0254e3f1af9223138e3faeac65b2c9d91bc22a9fc5a4a8bd8eb0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
