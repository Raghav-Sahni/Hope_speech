{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--ip=127.0.0.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from utils import *\n",
    "\n",
    "# helps in text preprocessing\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# helps in LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = os.path.join(os.path.abspath(os.path.join(os.getcwd(), os.pardir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_train = pd.read_csv(os.path.join(parent_dir, 'Data\\AugmentedData\\english_train_augmented.csv'))\n",
    "df_dev = pd.read_csv(os.path.join(parent_dir, 'Data\\PreprocessedData\\english_dev_preprocess.csv'))\n",
    "df_test = pd.read_csv(os.path.join(parent_dir, 'Data\\PreprocessedData\\english_test_preprocess.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[['augmented_text', 'label']]\n",
    "df_dev = df_dev[['preprocessed_text', 'label']]\n",
    "df_test = df_test[['preprocessed_text', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_replacement = {\n",
    "    'Hope_speech': 0,\n",
    "    'Non_hope_speech': 1,\n",
    "    'not-English': 2,\n",
    "}\n",
    "\n",
    "df_train['label'] = df_train['label'].replace(label_replacement)\n",
    "df_test['label'] = df_test['label'].replace(label_replacement)\n",
    "df_dev['label'] = df_dev['label'].replace(label_replacement)\n",
    "\n",
    "# Drop rows with label 2\n",
    "df_train = df_train[df_train['label'] != 2]\n",
    "df_test = df_test[df_test['label'] != 2]\n",
    "df_dev = df_dev[df_dev['label'] != 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = df_train['augmented_text'].to_numpy(), df_train['label'].to_numpy()\n",
    "X_dev, y_dev = df_dev['preprocessed_text'].to_numpy(), df_dev['label'].to_numpy()\n",
    "X_test, y_test = df_test['preprocessed_text'].to_numpy(), df_test['label'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Tokenizer()\n",
    "t.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_train = t.texts_to_sequences(X_train)\n",
    "encoded_dev = t.texts_to_sequences(X_dev)\n",
    "encoded_test = t.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 8\n",
    "padded_train = pad_sequences(encoded_train, maxlen=max_length, padding='post')\n",
    "padded_dev = pad_sequences(encoded_dev, maxlen=max_length, padding='post')\n",
    "padded_test = pad_sequences(encoded_test, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 8, 24)             521064    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 24)                4704      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 25        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 525,793\n",
      "Trainable params: 525,793\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(t.word_index) + 1\n",
    "\n",
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 24, input_length=max_length))\n",
    "model.add(LSTM(24, return_sequences=False))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# summarize the model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1324/1324 [==============================] - 12s 7ms/step - loss: 0.4674 - accuracy: 0.7732 - val_loss: 0.4464 - val_accuracy: 0.7909\n",
      "Epoch 2/100\n",
      "1324/1324 [==============================] - 8s 6ms/step - loss: 0.3479 - accuracy: 0.8479 - val_loss: 0.4080 - val_accuracy: 0.8233\n",
      "Epoch 3/100\n",
      "1324/1324 [==============================] - 8s 6ms/step - loss: 0.3052 - accuracy: 0.8720 - val_loss: 0.4078 - val_accuracy: 0.8275\n",
      "Epoch 4/100\n",
      "1324/1324 [==============================] - 7s 5ms/step - loss: 0.2746 - accuracy: 0.8873 - val_loss: 0.4407 - val_accuracy: 0.8124\n",
      "Epoch 5/100\n",
      "1324/1324 [==============================] - 7s 6ms/step - loss: 0.2506 - accuracy: 0.8989 - val_loss: 0.3648 - val_accuracy: 0.8483\n",
      "Epoch 6/100\n",
      "1324/1324 [==============================] - 7s 5ms/step - loss: 0.2292 - accuracy: 0.9080 - val_loss: 0.4071 - val_accuracy: 0.8307\n",
      "Epoch 7/100\n",
      "1324/1324 [==============================] - 6s 5ms/step - loss: 0.2096 - accuracy: 0.9178 - val_loss: 0.4468 - val_accuracy: 0.8152\n",
      "Epoch 8/100\n",
      "1324/1324 [==============================] - 6s 5ms/step - loss: 0.1924 - accuracy: 0.9247 - val_loss: 0.3919 - val_accuracy: 0.8518\n",
      "Epoch 8: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2007053efd0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3)\n",
    "\n",
    "# fit the model\n",
    "model.fit(\n",
    "    x=padded_train,\n",
    "    y=y_train,\n",
    "    epochs=100,\n",
    "    validation_data=(padded_dev, y_dev), verbose=1,\n",
    "    callbacks=[early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1324/1324 [==============================] - 2s 1ms/step\n",
      "89/89 [==============================] - 0s 2ms/step\n",
      "89/89 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "train_preds = model.predict(padded_train)\n",
    "dev_preds = model.predict(padded_dev)\n",
    "test_preds = model.predict(padded_test)\n",
    "\n",
    "train_preds = np.where(train_preds > 0.5, 1, 0)\n",
    "dev_preds = np.where(dev_preds > 0.5, 1, 0)\n",
    "test_preds = np.where(test_preds > 0.5, 1, 0)\n",
    "\n",
    "train_preds = train_preds.flatten()\n",
    "dev_preds = dev_preds.flatten()\n",
    "test_preds = test_preds.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Train:  0.934017941454202\n",
      "Accuracy Dev:  0.8518127419922562\n",
      "Accuracy Test:  0.8476960956735843\n",
      "Weighted F1 Train:  0.9339996834067715\n",
      "Weighted F1 Dev:  0.8659379211151943\n",
      "Weighted F1 Test:  0.8654456224760296\n",
      "Macro F1 Train:  0.9339637922817494\n",
      "Macro F1 Dev:  0.6566118795320398\n",
      "Macro F1 Test:  0.6406502641077624\n",
      "Micro F1 Train:  0.934017941454202\n",
      "Micro F1 Dev:  0.8518127419922562\n",
      "Micro F1 Test:  0.8476960956735843\n",
      "Weighted Recall Train:  0.934017941454202\n",
      "Weighted Recall Dev:  0.8518127419922562\n",
      "Weighted Recall Test:  0.8476960956735843\n",
      "Macro Recall Train:  0.9338108371129801\n",
      "Macro Recall Dev:  0.6994617669956266\n",
      "Macro Recall Test:  0.6924165059776322\n",
      "Micro Recall Train:  0.934017941454202\n",
      "Micro Recall Dev:  0.8518127419922562\n",
      "Micro Recall Test:  0.8476960956735843\n",
      "Confusion Matrix Train: \n",
      "[[20389  1193]\n",
      " [ 1602 19176]]\n",
      "Confusion Matrix Dev: \n",
      "[[ 139  133]\n",
      " [ 288 2281]]\n",
      "Confusion Matrix Test: \n",
      "[[ 126  124]\n",
      " [ 309 2284]]\n"
     ]
    }
   ],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a5a87ee616be0254e3f1af9223138e3faeac65b2c9d91bc22a9fc5a4a8bd8eb0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
