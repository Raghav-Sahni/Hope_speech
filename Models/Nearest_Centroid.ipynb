{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from embeddings_loader import *\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels, dev_labels, test_labels = load_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeAllScores(y_pred_train, y_pred_dev, y_pred_test):\n",
    "    print(\"Accuracy Train: \", accuracy_score(train_labels, y_pred_train))\n",
    "    print(\"Accuracy Dev: \", accuracy_score(dev_labels, y_pred_dev))\n",
    "    print(\"Accuracy Test: \", accuracy_score(test_labels, y_pred_test))\n",
    "    print(\"F1 Train: \", f1_score(train_labels, y_pred_train, average='macro'))\n",
    "    print(\"F1 Dev: \", f1_score(dev_labels, y_pred_dev, average='macro'))\n",
    "    print(\"F1 Test: \", f1_score(test_labels, y_pred_test, average='macro'))\n",
    "    print(\"Precision Train: \", precision_score(train_labels, y_pred_train, average='macro'))\n",
    "    print(\"Precision Dev: \", precision_score(dev_labels, y_pred_dev, average='macro'))\n",
    "    print(\"Precision Test: \", precision_score(test_labels, y_pred_test, average='macro'))\n",
    "    print(\"Recall Train: \", recall_score(train_labels, y_pred_train, average='macro'))\n",
    "    print(\"Recall Dev: \", recall_score(dev_labels, y_pred_dev, average='macro'))\n",
    "    print(\"Recall Test: \", recall_score(test_labels, y_pred_test, average='macro'))\n",
    "    # Confusion Matrix\n",
    "    print(\"Confusion Matrix Train: \")\n",
    "    print(confusion_matrix(train_labels, y_pred_train))\n",
    "    print(\"Confusion Matrix Dev: \")\n",
    "    print(confusion_matrix(dev_labels, y_pred_dev))\n",
    "    print(\"Confusion Matrix Test: \")\n",
    "    print(confusion_matrix(test_labels, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_replacement = {\n",
    "    'Hope_speech': 0,\n",
    "    'Non_hope_speech': 1,\n",
    "    'not-English': 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace labels with numbers\n",
    "train_labels = [label_replacement[label] for label in train_labels]\n",
    "dev_labels = [label_replacement[label] for label in dev_labels]\n",
    "test_labels = [label_replacement[label] for label in test_labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glove Twitter 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt25_train, gt25_dev, gt25_test = load_glove_twitter_25()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set all NaN values to 0\n",
    "gt25_train = np.nan_to_num(gt25_train)\n",
    "gt25_dev = np.nan_to_num(gt25_dev)\n",
    "gt25_test = np.nan_to_num(gt25_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_centroid = NearestCentroid().fit(gt25_train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = nearest_centroid.predict(gt25_train)\n",
    "dev_preds = nearest_centroid.predict(gt25_dev)\n",
    "test_preds = nearest_centroid.predict(gt25_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Train:  0.47970301379492136\n",
      "Accuracy Dev:  0.48997537812170244\n",
      "Accuracy Test:  0.4764581869290232\n",
      "F1 Train:  0.28734117594971553\n",
      "F1 Dev:  0.2980994632664367\n",
      "F1 Test:  0.28793564454140674\n",
      "Precision Train:  0.36637950347720394\n",
      "Precision Dev:  0.3707864273623076\n",
      "Precision Test:  0.3677315352310515\n",
      "Recall Train:  0.5636679644990306\n",
      "Recall Dev:  0.7329662110075638\n",
      "Recall Test:  0.5130018425675965\n",
      "Confusion Matrix Train: \n",
      "[[1443  455   64]\n",
      " [8757 9465 2556]\n",
      " [   5    6   11]]\n",
      "Confusion Matrix Dev: \n",
      "[[ 200   64    8]\n",
      " [1074 1191  304]\n",
      " [   0    0    2]]\n",
      "Confusion Matrix Test: \n",
      "[[ 189   57    4]\n",
      " [1090 1166  337]\n",
      " [   1    1    1]]\n"
     ]
    }
   ],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FastText 300 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft300_train, ft300_dev, ft300_test = load_fasttext_300()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set all NaN values to 0\n",
    "ft300_train = np.nan_to_num(ft300_train)\n",
    "ft300_dev = np.nan_to_num(ft300_dev)\n",
    "ft300_test = np.nan_to_num(ft300_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_centroid = NearestCentroid().fit(ft300_train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = nearest_centroid.predict(ft300_train)\n",
    "dev_preds = nearest_centroid.predict(ft300_dev)\n",
    "test_preds = nearest_centroid.predict(ft300_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Train:  0.6240664265003075\n",
      "Accuracy Dev:  0.6215265564544495\n",
      "Accuracy Test:  0.6289529163738581\n",
      "F1 Train:  0.3472252050771638\n",
      "F1 Dev:  0.35197322985265717\n",
      "F1 Test:  0.35126624153239455\n",
      "Precision Train:  0.3790820077272104\n",
      "Precision Dev:  0.38347846298226734\n",
      "Precision Test:  0.38232228019527303\n",
      "Recall Train:  0.5981714645664077\n",
      "Recall Dev:  0.6160523473694655\n",
      "Recall Test:  0.5663835111625316\n",
      "Confusion Matrix Train: \n",
      "[[ 1423   524    15]\n",
      " [ 7154 12772   852]\n",
      " [    4     8    10]]\n",
      "Confusion Matrix Dev: \n",
      "[[ 201   68    3]\n",
      " [ 895 1565  109]\n",
      " [   1    0    1]]\n",
      "Confusion Matrix Test: \n",
      "[[ 187   61    2]\n",
      " [ 876 1602  115]\n",
      " [   1    1    1]]\n"
     ]
    }
   ],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v300_train, w2v300_dev, w2v300_test = load_word2vec_300()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set all NaN values to 0\n",
    "w2v300_train = np.nan_to_num(w2v300_train)\n",
    "w2v300_dev = np.nan_to_num(w2v300_dev)\n",
    "w2v300_test = np.nan_to_num(w2v300_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_centroid = NearestCentroid().fit(w2v300_train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = nearest_centroid.predict(w2v300_train)\n",
    "dev_preds = nearest_centroid.predict(w2v300_dev)\n",
    "test_preds = nearest_centroid.predict(w2v300_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Train:  0.6600913803707934\n",
      "Accuracy Dev:  0.6630320084417869\n",
      "Accuracy Test:  0.6654954321855235\n",
      "F1 Train:  0.36425988909189205\n",
      "F1 Dev:  0.3729726712182186\n",
      "F1 Test:  0.37511734210431696\n",
      "Precision Train:  0.3855406107287565\n",
      "Precision Dev:  0.3916325969283716\n",
      "Precision Test:  0.3956594876316804\n",
      "Recall Train:  0.5980371562170766\n",
      "Recall Dev:  0.6335545798700952\n",
      "Recall Test:  0.6026436988473239\n",
      "Confusion Matrix Train: \n",
      "[[ 1435   511    16]\n",
      " [ 6446 13581   751]\n",
      " [    2    11     9]]\n",
      "Confusion Matrix Dev: \n",
      "[[ 203   68    1]\n",
      " [ 791 1681   97]\n",
      " [   0    1    1]]\n",
      "Confusion Matrix Test: \n",
      "[[ 206   44    0]\n",
      " [ 809 1687   97]\n",
      " [   1    1    1]]\n"
     ]
    }
   ],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF PCA (1000 Dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_pca_train, tfidf_pca_dev, tfidf_pca_test = load_tfidf_pca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_centroid = NearestCentroid().fit(tfidf_pca_train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = nearest_centroid.predict(tfidf_pca_train)\n",
    "dev_preds = nearest_centroid.predict(tfidf_pca_dev)\n",
    "test_preds = nearest_centroid.predict(tfidf_pca_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Train:  0.7730867234865126\n",
      "Accuracy Dev:  0.7583538515652479\n",
      "Accuracy Test:  0.7614195361911454\n",
      "F1 Train:  0.42529839422773147\n",
      "F1 Dev:  0.4121132839539076\n",
      "F1 Test:  0.4092289643846722\n",
      "Precision Train:  0.41369761860520576\n",
      "Precision Dev:  0.40898646970928704\n",
      "Precision Test:  0.40602382493910955\n",
      "Recall Train:  0.7393047956501185\n",
      "Recall Dev:  0.4846486959906578\n",
      "Recall Test:  0.48699781462912967\n",
      "Confusion Matrix Train: \n",
      "[[ 1298   635    29]\n",
      " [ 3737 16282   759]\n",
      " [    0     5    17]]\n",
      "Confusion Matrix Dev: \n",
      "[[ 187   78    7]\n",
      " [ 516 1969   84]\n",
      " [   0    2    0]]\n",
      "Confusion Matrix Test: \n",
      "[[ 173   73    4]\n",
      " [ 506 1994   93]\n",
      " [   0    3    0]]\n"
     ]
    }
   ],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Transformer Faster No PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, dev, test = load_sent_trans_fast_no_pca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_centroid = NearestCentroid().fit(train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = nearest_centroid.predict(train)\n",
    "dev_preds = nearest_centroid.predict(dev)\n",
    "test_preds = nearest_centroid.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Train:  0.7556014409981548\n",
      "Accuracy Dev:  0.7530777347871966\n",
      "Accuracy Test:  0.7484188334504568\n",
      "F1 Train:  0.43042788904055795\n",
      "F1 Dev:  0.42970491901065877\n",
      "F1 Test:  0.4228869061367528\n",
      "Precision Train:  0.42396122188485214\n",
      "Precision Dev:  0.4256519431690493\n",
      "Precision Test:  0.41997956405441167\n",
      "Recall Train:  0.7840566908790092\n",
      "Recall Dev:  0.6667711362474145\n",
      "Recall Test:  0.623343531730728\n",
      "Confusion Matrix Train: \n",
      "[[ 1532   367    63]\n",
      " [ 3918 15649  1211]\n",
      " [    1     3    18]]\n",
      "Confusion Matrix Dev: \n",
      "[[ 203   59   10]\n",
      " [ 471 1937  161]\n",
      " [   0    1    1]]\n",
      "Confusion Matrix Test: \n",
      "[[ 198   46    6]\n",
      " [ 515 1931  147]\n",
      " [   0    2    1]]\n"
     ]
    }
   ],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Transformer Faster PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, dev, test = load_sent_trans_fast_pca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_centroid = NearestCentroid().fit(train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = nearest_centroid.predict(train)\n",
    "dev_preds = nearest_centroid.predict(dev)\n",
    "test_preds = nearest_centroid.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Train:  0.7510763553290573\n",
      "Accuracy Dev:  0.748153359127682\n",
      "Accuracy Test:  0.7452565003513704\n",
      "F1 Train:  0.42866522750059516\n",
      "F1 Dev:  0.42754941404575364\n",
      "F1 Test:  0.4222541821900796\n",
      "Precision Train:  0.4236775774544243\n",
      "Precision Dev:  0.4249705883392217\n",
      "Precision Test:  0.4201772845295531\n",
      "Recall Train:  0.781942745966091\n",
      "Recall Dev:  0.6638588677978003\n",
      "Recall Test:  0.62218657068175\n",
      "Confusion Matrix Train: \n",
      "[[ 1529   363    70]\n",
      " [ 3906 15549  1323]\n",
      " [    1     3    18]]\n",
      "Confusion Matrix Dev: \n",
      "[[ 202   58   12]\n",
      " [ 473 1924  172]\n",
      " [   0    1    1]]\n",
      "Confusion Matrix Test: \n",
      "[[ 198   46    6]\n",
      " [ 512 1922  159]\n",
      " [   0    2    1]]\n"
     ]
    }
   ],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Transformer Better No PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, dev, test = load_sent_trans_better_no_pca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_centroid = NearestCentroid().fit(train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = nearest_centroid.predict(train)\n",
    "dev_preds = nearest_centroid.predict(dev)\n",
    "test_preds = nearest_centroid.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Train:  0.7425094455671734\n",
      "Accuracy Dev:  0.7463946535349982\n",
      "Accuracy Test:  0.7371749824314828\n",
      "F1 Train:  0.43146778920882695\n",
      "F1 Dev:  0.4350685830431395\n",
      "F1 Test:  0.43059630707966057\n",
      "Precision Train:  0.429967689934548\n",
      "Precision Dev:  0.43422554551193193\n",
      "Precision Test:  0.43090798999843744\n",
      "Recall Train:  0.7491589003178095\n",
      "Recall Dev:  0.5098220487104924\n",
      "Recall Test:  0.621639456656811\n",
      "Confusion Matrix Train: \n",
      "[[ 1533   324   105]\n",
      " [ 3526 15352  1900]\n",
      " [    2     4    16]]\n",
      "Confusion Matrix Dev: \n",
      "[[ 214   45   13]\n",
      " [ 441 1908  220]\n",
      " [   0    2    0]]\n",
      "Confusion Matrix Test: \n",
      "[[ 200   39   11]\n",
      " [ 445 1897  251]\n",
      " [   0    2    1]]\n"
     ]
    }
   ],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Transformer Better PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, dev, test = load_sent_trans_better_pca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_centroid = NearestCentroid().fit(train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = nearest_centroid.predict(train)\n",
    "dev_preds = nearest_centroid.predict(dev)\n",
    "test_preds = nearest_centroid.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Train:  0.7367981723925842\n",
      "Accuracy Dev:  0.7390080900457263\n",
      "Accuracy Test:  0.7340126493323963\n",
      "F1 Train:  0.42968197136857356\n",
      "F1 Dev:  0.43296881250700076\n",
      "F1 Test:  0.4294071270047755\n",
      "Precision Train:  0.4297372460239302\n",
      "Precision Dev:  0.4339658081101865\n",
      "Precision Test:  0.4306354203541127\n",
      "Recall Train:  0.7467656570134403\n",
      "Recall Dev:  0.5060015150474358\n",
      "Recall Test:  0.619277713502164\n",
      "Confusion Matrix Train: \n",
      "[[ 1531   321   110]\n",
      " [ 3525 15224  2029]\n",
      " [    2     4    16]]\n",
      "Confusion Matrix Dev: \n",
      "[[ 213   45   14]\n",
      " [ 440 1888  241]\n",
      " [   0    2    0]]\n",
      "Confusion Matrix Test: \n",
      "[[ 199   39   12]\n",
      " [ 444 1889  260]\n",
      " [   0    2    1]]\n"
     ]
    }
   ],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a5a87ee616be0254e3f1af9223138e3faeac65b2c9d91bc22a9fc5a4a8bd8eb0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
