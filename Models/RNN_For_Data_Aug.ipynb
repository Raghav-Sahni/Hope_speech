{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--ip=127.0.0.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from utils import *\n",
    "\n",
    "# helps in text preprocessing\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# helps in model building\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import SimpleRNN\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = os.path.join(os.path.abspath(os.path.join(os.getcwd(), os.pardir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_train = pd.read_csv(os.path.join(parent_dir, 'Data\\AugmentedData\\english_train_augmented.csv'))\n",
    "df_dev = pd.read_csv(os.path.join(parent_dir, 'Data\\PreprocessedData\\english_dev_preprocess.csv'))\n",
    "df_test = pd.read_csv(os.path.join(parent_dir, 'Data\\PreprocessedData\\english_test_preprocess.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[['augmented_text', 'label']]\n",
    "df_dev = df_dev[['preprocessed_text', 'label']]\n",
    "df_test = df_test[['preprocessed_text', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_replacement = {\n",
    "    'Hope_speech': 0,\n",
    "    'Non_hope_speech': 1,\n",
    "    'not-English': 2,\n",
    "}\n",
    "\n",
    "df_train['label'] = df_train['label'].replace(label_replacement)\n",
    "df_test['label'] = df_test['label'].replace(label_replacement)\n",
    "df_dev['label'] = df_dev['label'].replace(label_replacement)\n",
    "\n",
    "# Drop rows with label 2\n",
    "df_train = df_train[df_train['label'] != 2]\n",
    "df_test = df_test[df_test['label'] != 2]\n",
    "df_dev = df_dev[df_dev['label'] != 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = df_train['augmented_text'].to_numpy(), df_train['label'].to_numpy()\n",
    "X_dev, y_dev = df_dev['preprocessed_text'].to_numpy(), df_dev['label'].to_numpy()\n",
    "X_test, y_test = df_test['preprocessed_text'].to_numpy(), df_test['label'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Tokenizer()\n",
    "t.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_train = t.texts_to_sequences(X_train)\n",
    "encoded_dev = t.texts_to_sequences(X_dev)\n",
    "encoded_test = t.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 8\n",
    "padded_train = pad_sequences(encoded_train, maxlen=max_length, padding='post')\n",
    "padded_dev = pad_sequences(encoded_dev, maxlen=max_length, padding='post')\n",
    "padded_test = pad_sequences(encoded_test, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 8, 24)             521064    \n",
      "                                                                 \n",
      " simple_rnn (SimpleRNN)      (None, 24)                1176      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 25        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 522,265\n",
      "Trainable params: 522,265\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(t.word_index) + 1\n",
    "\n",
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 24, input_length=max_length))\n",
    "model.add(SimpleRNN(24, return_sequences=False))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# summarize the model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1324/1324 [==============================] - 6s 3ms/step - loss: 0.4508 - accuracy: 0.7819 - val_loss: 0.3840 - val_accuracy: 0.8374\n",
      "Epoch 2/100\n",
      "1324/1324 [==============================] - 5s 4ms/step - loss: 0.2913 - accuracy: 0.8773 - val_loss: 0.4171 - val_accuracy: 0.8296\n",
      "Epoch 3/100\n",
      "1324/1324 [==============================] - 5s 4ms/step - loss: 0.2297 - accuracy: 0.9076 - val_loss: 0.4101 - val_accuracy: 0.8391\n",
      "Epoch 4/100\n",
      "1324/1324 [==============================] - 5s 4ms/step - loss: 0.1985 - accuracy: 0.9212 - val_loss: 0.3760 - val_accuracy: 0.8539\n",
      "Epoch 5/100\n",
      "1324/1324 [==============================] - 5s 4ms/step - loss: 0.1782 - accuracy: 0.9314 - val_loss: 0.4081 - val_accuracy: 0.8479\n",
      "Epoch 6/100\n",
      "1324/1324 [==============================] - 5s 4ms/step - loss: 0.1658 - accuracy: 0.9378 - val_loss: 0.4207 - val_accuracy: 0.8370\n",
      "Epoch 7/100\n",
      "1324/1324 [==============================] - 5s 4ms/step - loss: 0.1556 - accuracy: 0.9411 - val_loss: 0.3921 - val_accuracy: 0.8515\n",
      "Epoch 7: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b02af76130>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3)\n",
    "\n",
    "# fit the model\n",
    "model.fit(\n",
    "    x=padded_train,\n",
    "    y=y_train,\n",
    "    epochs=100,\n",
    "    validation_data=(padded_dev, y_dev), verbose=1,\n",
    "    callbacks=[early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1324/1324 [==============================] - 3s 2ms/step\n",
      "89/89 [==============================] - 0s 2ms/step\n",
      "89/89 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "train_preds = model.predict(padded_train)\n",
    "dev_preds = model.predict(padded_dev)\n",
    "test_preds = model.predict(padded_test)\n",
    "\n",
    "train_preds = np.where(train_preds > 0.5, 1, 0)\n",
    "dev_preds = np.where(dev_preds > 0.5, 1, 0)\n",
    "test_preds = np.where(test_preds > 0.5, 1, 0)\n",
    "\n",
    "train_preds = train_preds.flatten()\n",
    "dev_preds = dev_preds.flatten()\n",
    "test_preds = test_preds.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Train:  0.9521246458923512\n",
      "Accuracy Dev:  0.8514607532558958\n",
      "Accuracy Test:  0.8519169890960253\n",
      "Weighted F1 Train:  0.9521278260542252\n",
      "Weighted F1 Dev:  0.8618461949325626\n",
      "Weighted F1 Test:  0.8665794297608288\n",
      "Macro F1 Train:  0.9521147809004158\n",
      "Macro F1 Dev:  0.6324677379007931\n",
      "Macro F1 Test:  0.6328780795728404\n",
      "Micro F1 Train:  0.9521246458923512\n",
      "Micro F1 Dev:  0.8514607532558958\n",
      "Micro F1 Test:  0.8519169890960253\n",
      "Weighted Recall Train:  0.9521246458923512\n",
      "Weighted Recall Dev:  0.8514607532558958\n",
      "Weighted Recall Test:  0.8519169890960253\n",
      "Macro Recall Train:  0.9521952457520335\n",
      "Macro Recall Dev:  0.6565333558491516\n",
      "Macro Recall Test:  0.6712371770150405\n",
      "Micro Recall Train:  0.9521246458923512\n",
      "Micro Recall Dev:  0.8514607532558958\n",
      "Micro Recall Test:  0.8519169890960253\n",
      "Confusion Matrix Train: \n",
      "[[20470  1112]\n",
      " [  916 19862]]\n",
      "Confusion Matrix Dev: \n",
      "[[ 113  159]\n",
      " [ 263 2306]]\n",
      "Confusion Matrix Test: \n",
      "[[ 113  137]\n",
      " [ 284 2309]]\n"
     ]
    }
   ],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a5a87ee616be0254e3f1af9223138e3faeac65b2c9d91bc22a9fc5a4a8bd8eb0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
