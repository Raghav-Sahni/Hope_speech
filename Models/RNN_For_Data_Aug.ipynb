{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--ip=127.0.0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\requests\\__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (5.0.0)/charset_normalizer (2.0.10) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from utils import *\n",
    "\n",
    "# helps in text preprocessing\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# helps in model building\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import SimpleRNN\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = os.path.join(os.path.abspath(os.path.join(os.getcwd(), os.pardir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_train = pd.read_csv(os.path.join(parent_dir, 'Data\\AugmentedData\\english_train_augmented.csv'))\n",
    "df_dev = pd.read_csv(os.path.join(parent_dir, 'Data\\PreprocessedData\\english_dev_preprocess.csv'))\n",
    "df_test = pd.read_csv(os.path.join(parent_dir, 'Data\\PreprocessedData\\english_test_preprocess.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[['augmented_text', 'label']]\n",
    "df_dev = df_dev[['preprocessed_text', 'label']]\n",
    "df_test = df_test[['preprocessed_text', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_replacement = {\n",
    "    'Hope_speech': 0,\n",
    "    'Non_hope_speech': 1,\n",
    "    'not-English': 2,\n",
    "}\n",
    "\n",
    "df_train['label'] = df_train['label'].replace(label_replacement)\n",
    "df_test['label'] = df_test['label'].replace(label_replacement)\n",
    "df_dev['label'] = df_dev['label'].replace(label_replacement)\n",
    "\n",
    "# Drop rows with label 2\n",
    "df_train = df_train[df_train['label'] != 2]\n",
    "df_test = df_test[df_test['label'] != 2]\n",
    "df_dev = df_dev[df_dev['label'] != 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = df_train['augmented_text'].to_numpy(), df_train['label'].to_numpy()\n",
    "X_dev, y_dev = df_dev['preprocessed_text'].to_numpy(), df_dev['label'].to_numpy()\n",
    "X_test, y_test = df_test['preprocessed_text'].to_numpy(), df_test['label'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Tokenizer()\n",
    "t.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_train = t.texts_to_sequences(X_train)\n",
    "encoded_dev = t.texts_to_sequences(X_dev)\n",
    "encoded_test = t.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 8\n",
    "padded_train = pad_sequences(encoded_train, maxlen=max_length, padding='post')\n",
    "padded_dev = pad_sequences(encoded_dev, maxlen=max_length, padding='post')\n",
    "padded_test = pad_sequences(encoded_test, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 8, 24)             521064    \n",
      "                                                                 \n",
      " simple_rnn (SimpleRNN)      (None, 24)                1176      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 25        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 522,265\n",
      "Trainable params: 522,265\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(t.word_index) + 1\n",
    "\n",
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 24, input_length=max_length))\n",
    "model.add(SimpleRNN(24, return_sequences=False))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# summarize the model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1324/1324 [==============================] - 7s 4ms/step - loss: 0.4588 - accuracy: 0.7751 - val_loss: 0.4631 - val_accuracy: 0.7916\n",
      "Epoch 2/100\n",
      "1324/1324 [==============================] - 5s 4ms/step - loss: 0.2906 - accuracy: 0.8794 - val_loss: 0.3836 - val_accuracy: 0.8423\n",
      "Epoch 3/100\n",
      "1324/1324 [==============================] - 5s 4ms/step - loss: 0.2296 - accuracy: 0.9085 - val_loss: 0.4130 - val_accuracy: 0.8332\n",
      "Epoch 4/100\n",
      "1324/1324 [==============================] - 5s 4ms/step - loss: 0.1955 - accuracy: 0.9238 - val_loss: 0.4090 - val_accuracy: 0.8455\n",
      "Epoch 5/100\n",
      "1324/1324 [==============================] - 5s 4ms/step - loss: 0.1759 - accuracy: 0.9317 - val_loss: 0.4144 - val_accuracy: 0.8462\n",
      "Epoch 5: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f426fd7a00>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3)\n",
    "\n",
    "# fit the model\n",
    "model.fit(\n",
    "    x=padded_train,\n",
    "    y=y_train,\n",
    "    epochs=100,\n",
    "    validation_data=(padded_dev, y_dev), verbose=1,\n",
    "    callbacks=[early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1324/1324 [==============================] - 3s 2ms/step\n",
      "89/89 [==============================] - 0s 2ms/step\n",
      "89/89 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "train_preds = model.predict(padded_train)\n",
    "dev_preds = model.predict(padded_dev)\n",
    "test_preds = model.predict(padded_test)\n",
    "\n",
    "train_preds = np.where(train_preds > 0.5, 1, 0)\n",
    "dev_preds = np.where(dev_preds > 0.5, 1, 0)\n",
    "test_preds = np.where(test_preds > 0.5, 1, 0)\n",
    "\n",
    "train_preds = train_preds.flatten()\n",
    "dev_preds = dev_preds.flatten()\n",
    "test_preds = test_preds.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Train:  0.9429414542020774\n",
      "Accuracy Dev:  0.8461809222104892\n",
      "Accuracy Test:  0.8483995779106578\n",
      "Weighted F1 Train:  0.9429406307738535\n",
      "Weighted F1 Dev:  0.859987934456762\n",
      "Weighted F1 Test:  0.8645754536440421\n",
      "Macro F1 Train:  0.942919274764434\n",
      "Macro F1 Dev:  0.6382067657176828\n",
      "Macro F1 Test:  0.6320596447893236\n",
      "Micro F1 Train:  0.9429414542020774\n",
      "Micro F1 Dev:  0.8461809222104892\n",
      "Micro F1 Test:  0.8483995779106578\n",
      "Weighted Recall Train:  0.9429414542020774\n",
      "Weighted Recall Dev:  0.8461809222104892\n",
      "Weighted Recall Test:  0.8483995779106578\n",
      "Macro Recall Train:  0.9429069965123448\n",
      "Macro Recall Dev:  0.6733372163579328\n",
      "Macro Recall Test:  0.6747304280755881\n",
      "Micro Recall Train:  0.9429414542020774\n",
      "Micro Recall Dev:  0.8461809222104892\n",
      "Micro Recall Test:  0.8483995779106578\n",
      "Confusion Matrix Train: \n",
      "[[20389  1193]\n",
      " [ 1224 19554]]\n",
      "Confusion Matrix Dev: \n",
      "[[ 125  147]\n",
      " [ 290 2279]]\n",
      "Confusion Matrix Test: \n",
      "[[ 116  134]\n",
      " [ 297 2296]]\n"
     ]
    }
   ],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a5a87ee616be0254e3f1af9223138e3faeac65b2c9d91bc22a9fc5a4a8bd8eb0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
