{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--ip=127.0.0.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from utils import *\n",
    "\n",
    "# helps in text preprocessing\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# helps in LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = os.path.join(os.path.abspath(os.path.join(os.getcwd(), os.pardir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_train = pd.read_csv(os.path.join(parent_dir, 'Data\\PreprocessedData\\english_train_preprocess.csv'))\n",
    "df_dev = pd.read_csv(os.path.join(parent_dir, 'Data\\PreprocessedData\\english_dev_preprocess.csv'))\n",
    "df_test = pd.read_csv(os.path.join(parent_dir, 'Data\\PreprocessedData\\english_test_preprocess.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[['preprocessed_text', 'label']]\n",
    "df_dev = df_dev[['preprocessed_text', 'label']]\n",
    "df_test = df_test[['preprocessed_text', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_replacement = {\n",
    "    'Hope_speech': 0,\n",
    "    'Non_hope_speech': 1,\n",
    "    'not-English': 2,\n",
    "}\n",
    "\n",
    "df_train['label'] = df_train['label'].replace(label_replacement)\n",
    "df_test['label'] = df_test['label'].replace(label_replacement)\n",
    "df_dev['label'] = df_dev['label'].replace(label_replacement)\n",
    "\n",
    "# Drop rows with label 2\n",
    "df_train = df_train[df_train['label'] != 2]\n",
    "df_test = df_test[df_test['label'] != 2]\n",
    "df_dev = df_dev[df_dev['label'] != 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = df_train['preprocessed_text'].to_numpy(), df_train['label'].to_numpy()\n",
    "X_dev, y_dev = df_dev['preprocessed_text'].to_numpy(), df_dev['label'].to_numpy()\n",
    "X_test, y_test = df_test['preprocessed_text'].to_numpy(), df_test['label'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Tokenizer()\n",
    "t.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_train = t.texts_to_sequences(X_train)\n",
    "encoded_dev = t.texts_to_sequences(X_dev)\n",
    "encoded_test = t.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 8\n",
    "padded_train = pad_sequences(encoded_train, maxlen=max_length, padding='post')\n",
    "padded_dev = pad_sequences(encoded_dev, maxlen=max_length, padding='post')\n",
    "padded_test = pad_sequences(encoded_test, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 8, 24)             479640    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 24)                4704      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 25        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 484,369\n",
      "Trainable params: 484,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(t.word_index) + 1\n",
    "\n",
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 24, input_length=max_length))\n",
    "model.add(LSTM(24, return_sequences=False))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# summarize the model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "711/711 [==============================] - 5s 5ms/step - loss: 0.2859 - accuracy: 0.9128 - val_loss: 0.2685 - val_accuracy: 0.9050\n",
      "Epoch 2/100\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 0.2602 - accuracy: 0.9145 - val_loss: 0.2647 - val_accuracy: 0.9078\n",
      "Epoch 3/100\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 0.2540 - accuracy: 0.9151 - val_loss: 0.2622 - val_accuracy: 0.9092\n",
      "Epoch 4/100\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 0.2484 - accuracy: 0.9167 - val_loss: 0.2622 - val_accuracy: 0.9102\n",
      "Epoch 5/100\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 0.2432 - accuracy: 0.9182 - val_loss: 0.2626 - val_accuracy: 0.9092\n",
      "Epoch 6/100\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 0.2372 - accuracy: 0.9195 - val_loss: 0.2621 - val_accuracy: 0.9124\n",
      "Epoch 7/100\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 0.2314 - accuracy: 0.9213 - val_loss: 0.2592 - val_accuracy: 0.9088\n",
      "Epoch 8/100\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 0.2249 - accuracy: 0.9227 - val_loss: 0.2746 - val_accuracy: 0.9060\n",
      "Epoch 9/100\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 0.2176 - accuracy: 0.9240 - val_loss: 0.2692 - val_accuracy: 0.9064\n",
      "Epoch 10/100\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 0.2106 - accuracy: 0.9252 - val_loss: 0.2670 - val_accuracy: 0.9092\n",
      "Epoch 10: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20d6f45e0d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3)\n",
    "\n",
    "# fit the model\n",
    "model.fit(\n",
    "    x=padded_train,\n",
    "    y=y_train,\n",
    "    epochs=100,\n",
    "    validation_data=(padded_dev, y_dev), verbose=1,\n",
    "    callbacks=[early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "711/711 [==============================] - 1s 2ms/step\n",
      "89/89 [==============================] - 0s 2ms/step\n",
      "89/89 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "train_preds = model.predict(padded_train)\n",
    "dev_preds = model.predict(padded_dev)\n",
    "test_preds = model.predict(padded_test)\n",
    "\n",
    "train_preds = np.where(train_preds > 0.5, 1, 0)\n",
    "dev_preds = np.where(dev_preds > 0.5, 1, 0)\n",
    "test_preds = np.where(test_preds > 0.5, 1, 0)\n",
    "\n",
    "train_preds = train_preds.flatten()\n",
    "dev_preds = dev_preds.flatten()\n",
    "test_preds = test_preds.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Train:  0.9281442392260334\n",
      "Accuracy Dev:  0.9091869060190074\n",
      "Accuracy Test:  0.9099542736545903\n",
      "Weighted F1 Train:  0.9105945970591142\n",
      "Weighted F1 Dev:  0.8848876882737164\n",
      "Weighted F1 Test:  0.8908517109541166\n",
      "Macro F1 Train:  0.664533444292532\n",
      "Macro F1 Dev:  0.6029922177639504\n",
      "Macro F1 Test:  0.6039459134720033\n",
      "Micro F1 Train:  0.9281442392260334\n",
      "Micro F1 Dev:  0.9091869060190074\n",
      "Micro F1 Test:  0.9099542736545903\n",
      "Weighted Recall Train:  0.9281442392260334\n",
      "Weighted Recall Dev:  0.9091869060190074\n",
      "Weighted Recall Test:  0.9099542736545903\n",
      "Macro Recall Train:  0.6172817756254189\n",
      "Macro Recall Dev:  0.5750435051404759\n",
      "Macro Recall Test:  0.5783586579251832\n",
      "Micro Recall Train:  0.9281442392260334\n",
      "Micro Recall Dev:  0.9091869060190074\n",
      "Micro Recall Test:  0.9099542736545903\n",
      "Confusion Matrix Train: \n",
      "[[  474  1488]\n",
      " [  146 20632]]\n",
      "Confusion Matrix Dev: \n",
      "[[  44  228]\n",
      " [  30 2539]]\n",
      "Confusion Matrix Test: \n",
      "[[  44  206]\n",
      " [  50 2543]]\n"
     ]
    }
   ],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a5a87ee616be0254e3f1af9223138e3faeac65b2c9d91bc22a9fc5a4a8bd8eb0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
