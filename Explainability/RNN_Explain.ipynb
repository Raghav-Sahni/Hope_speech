{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\requests\\__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (5.0.0)/charset_normalizer (2.0.10) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "# from utils import *\n",
    "\n",
    "# helps in text preprocessing\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# helps in model building\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import SimpleRNN\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Explaining the model\n",
    "import ktrain\n",
    "from ktrain import text\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = os.path.join(os.path.abspath(os.path.join(os.getcwd(), os.pardir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_train = pd.read_csv(os.path.join(parent_dir, 'Data\\PreprocessedData\\english_train_preprocess.csv'))\n",
    "df_dev = pd.read_csv(os.path.join(parent_dir, 'Data\\PreprocessedData\\english_dev_preprocess.csv'))\n",
    "df_test = pd.read_csv(os.path.join(parent_dir, 'Data\\PreprocessedData\\english_test_preprocess.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[['preprocessed_text', 'label']]\n",
    "df_dev = df_dev[['preprocessed_text', 'label']]\n",
    "df_test = df_test[['preprocessed_text', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_replacement = {\n",
    "    'Hope_speech': 0,\n",
    "    'Non_hope_speech': 1,\n",
    "    'not-English': 2,\n",
    "}\n",
    "\n",
    "df_train['label'] = df_train['label'].replace(label_replacement)\n",
    "df_test['label'] = df_test['label'].replace(label_replacement)\n",
    "df_dev['label'] = df_dev['label'].replace(label_replacement)\n",
    "\n",
    "# Drop rows with label 2\n",
    "df_train = df_train[df_train['label'] != 2]\n",
    "df_test = df_test[df_test['label'] != 2]\n",
    "df_dev = df_dev[df_dev['label'] != 2]\n",
    "\n",
    "# Create Index Column\n",
    "df_train['index'] = df_train.index\n",
    "df_test['index'] = df_test.index\n",
    "df_dev['index'] = df_dev.index\n",
    "\n",
    "# Rename Columns\n",
    "df_train = df_train.rename(columns={'preprocessed_text': 'text', 'label': 'label'})\n",
    "df_test = df_test.rename(columns={'preprocessed_text': 'text', 'label': 'label'})\n",
    "df_dev = df_dev.rename(columns={'preprocessed_text': 'text', 'label': 'label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['not_label', 'label']\n",
      "   not_label  label\n",
      "0        0.0    1.0\n",
      "1        0.0    1.0\n",
      "2        0.0    1.0\n",
      "3        0.0    1.0\n",
      "4        0.0    1.0\n",
      "['not_label', 'label']\n",
      "   not_label  label\n",
      "0        0.0    1.0\n",
      "1        0.0    1.0\n",
      "2        0.0    1.0\n",
      "3        0.0    1.0\n",
      "4        1.0    0.0\n",
      "language: en\n",
      "Word Counts: 19984\n",
      "Nrows: 22740\n",
      "22740 train sequences\n",
      "train sequence lengths:\n",
      "\tmean : 17\n",
      "\t95percentile : 46\n",
      "\t99percentile : 86\n",
      "x_train shape: (22740,400)\n",
      "y_train shape: (22740, 2)\n",
      "Is Multi-Label? False\n",
      "2841 test sequences\n",
      "test sequence lengths:\n",
      "\tmean : 16\n",
      "\t95percentile : 45\n",
      "\t99percentile : 85\n",
      "x_test shape: (2841,400)\n",
      "y_test shape: (2841, 2)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, preproc = text.texts_from_df(train_df=df_train, text_column='text', label_columns='label', val_df=df_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = df_train['text'].to_numpy(), df_train['label'].to_numpy()\n",
    "X_dev, y_dev = df_dev['text'].to_numpy(), df_dev['label'].to_numpy()\n",
    "X_test, y_test = df_test['text'].to_numpy(), df_test['label'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Tokenizer()\n",
    "t.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 400, 24)           479640    \n",
      "                                                                 \n",
      " simple_rnn (SimpleRNN)      (None, 24)                1176      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 50        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 480,866\n",
      "Trainable params: 480,866\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(t.word_index) + 1\n",
    "\n",
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 24, input_length=max_length))\n",
    "model.add(SimpleRNN(24, return_sequences=False))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# summarize the model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "begin training using triangular learning rate policy with max lr of 0.005...\n",
      "Epoch 1/10\n",
      "711/711 [==============================] - 57s 79ms/step - loss: 0.2876 - accuracy: 0.9128 - val_loss: 0.2633 - val_accuracy: 0.9099\n",
      "Epoch 2/10\n",
      "711/711 [==============================] - 50s 70ms/step - loss: 0.1973 - accuracy: 0.9278 - val_loss: 0.2590 - val_accuracy: 0.9109\n",
      "Epoch 3/10\n",
      "711/711 [==============================] - 48s 68ms/step - loss: 0.1305 - accuracy: 0.9526 - val_loss: 0.2703 - val_accuracy: 0.9014\n",
      "Epoch 4/10\n",
      "711/711 [==============================] - 48s 67ms/step - loss: 0.1668 - accuracy: 0.9385 - val_loss: 0.3183 - val_accuracy: 0.8986\n",
      "Epoch 5/10\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.1567 - accuracy: 0.9396Restoring model weights from the end of the best epoch: 2.\n",
      "711/711 [==============================] - 48s 67ms/step - loss: 0.1567 - accuracy: 0.9396 - val_loss: 0.3261 - val_accuracy: 0.8937\n",
      "Epoch 5: early stopping\n",
      "Weights from best epoch have been loaded into model.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cb5431e4c0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 24, input_length=400)) # add 1 for padding token\n",
    "model.add(SimpleRNN(24, return_sequences=False))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "learner = ktrain.get_learner(model, train_data=x_train, val_data=x_test)\n",
    "\n",
    "# STEP 3: train\n",
    "learner.autofit(0.005, 10, early_stopping=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 2s 21ms/step\n",
      "----------\n",
      "id:2062 | loss:5.26 | true:not_label | pred:label)\n",
      "\n",
      "it happens in my country scum politician using rasism as a means to get power back once they lost it in elections it works people are like sheep especially people that sit on thier asses all day\n",
      "----------\n",
      "id:2782 | loss:5.1 | true:not_label | pred:label)\n",
      "\n",
      "the walls came down in this interview\n",
      "----------\n",
      "id:1830 | loss:4.98 | true:not_label | pred:label)\n",
      "\n",
      "i am saying all lives matter and i say law matter s and we need our cops and fire and we need to support our law and mostly our cops i hope our government or governors start supporting our cops let them do their job and i think they need a raise i think we need to stop charging them with dum stuff yes some need to go to jail the one who choked that guy yes but the one with a gun no he just doing his job give him a raise good cop\n",
      "----------\n",
      "id:1267 | loss:4.97 | true:not_label | pred:label)\n",
      "\n",
      "nursing is a major because of societal pressure against the men who do it when colleges tried to males in nursing\n",
      "----------\n",
      "id:144 | loss:4.89 | true:not_label | pred:label)\n",
      "\n",
      "she taught me how to be bold and unapologeticthanks madge\n"
     ]
    }
   ],
   "source": [
    "learner.view_top_losses(n=5, preproc=preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n",
      "79/79 [==============================] - 1s 18ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "\n",
       "        \n",
       "\n",
       "        \n",
       "    \n",
       "        \n",
       "        \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=label\n",
       "    \n",
       "</b>\n",
       "\n",
       "    \n",
       "    (probability <b>0.999</b>, score <b>7.436</b>)\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
       "                    Contribution<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +6.769\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        Highlighted in text (sum)\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 96.05%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.667\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
       "        <span style=\"background-color: hsl(120, 100.00%, 77.45%); opacity: 0.89\" title=\"0.569\">thats</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 83.03%); opacity: 0.86\" title=\"0.379\">it</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 82.83%); opacity: 0.86\" title=\"0.385\">likei</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 72.70%); opacity: 0.92\" title=\"0.747\">dont</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 63.23%); opacity: 0.98\" title=\"1.144\">like</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 65.67%); opacity: 0.96\" title=\"1.037\">that</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"1.290\">statue</span>\n",
       "    </p>\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor = ktrain.get_predictor(learner.model, preproc)\n",
    "# Dev Set List\n",
    "dev_set = df_dev['text'].to_list()\n",
    "# Choose Random Text\n",
    "random_text = dev_set[0]\n",
    "\n",
    "predictor.explain(random_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a5a87ee616be0254e3f1af9223138e3faeac65b2c9d91bc22a9fc5a4a8bd8eb0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
